"""
CPUå‹åŠ›æµ‹è¯•æ¨¡å—
ç”¨äºè¯Šæ–­CPUä½¿ç”¨ç‡ä½çš„é—®é¢˜ï¼Œæ‰¾å‡ºçœŸæ­£çš„ç“¶é¢ˆ
"""

import os
import time
import threading
import numpy as np
import tensorflow as tf
from typing import Dict, List


def cpu_intensive_test(duration=30, num_threads=None):
    """
    CPUå¯†é›†å‹è®¡ç®—æµ‹è¯•
    
    Args:
        duration: æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
        num_threads: çº¿ç¨‹æ•°ï¼ŒNoneä¸ºè‡ªåŠ¨æ£€æµ‹
    """
    if num_threads is None:
        num_threads = os.cpu_count()
    
    print(f"ğŸ”¥ å¯åŠ¨CPUå‹åŠ›æµ‹è¯• ({duration}ç§’, {num_threads}çº¿ç¨‹)")
    
    def cpu_worker():
        """CPUå¯†é›†å‹è®¡ç®—å·¥ä½œçº¿ç¨‹"""
        end_time = time.time() + duration
        while time.time() < end_time:
            # çŸ©é˜µä¹˜æ³•è®¡ç®—
            a = np.random.random((100, 100))
            b = np.random.random((100, 100))
            np.dot(a, b)
    
    # å¯åŠ¨å·¥ä½œçº¿ç¨‹
    threads = []
    start_time = time.time()
    
    for i in range(num_threads):
        t = threading.Thread(target=cpu_worker)
        t.start()
        threads.append(t)
    
    # ç›‘æ§CPUä½¿ç”¨ç‡
    try:
        import psutil
        while time.time() - start_time < duration:
            cpu_percent = psutil.cpu_percent(interval=1)
            print(f"CPUä½¿ç”¨ç‡: {cpu_percent:.1f}%")
    except ImportError:
        print("æœªå®‰è£…psutilï¼Œæ— æ³•ç›‘æ§CPUä½¿ç”¨ç‡")
        time.sleep(duration)
    
    # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for t in threads:
        t.join()
    
    print("âœ… CPUå‹åŠ›æµ‹è¯•å®Œæˆ")


def tensorflow_compute_test(batch_sizes=[32, 64, 128, 256], duration=60):
    """
    TensorFlowè®¡ç®—æµ‹è¯•
    
    Args:
        batch_sizes: è¦æµ‹è¯•çš„æ‰¹æ¬¡å¤§å°åˆ—è¡¨
        duration: æ¯ä¸ªæ‰¹æ¬¡å¤§å°çš„æµ‹è¯•æ—¶é—´
    """
    print(f"ğŸ§ª TensorFlowè®¡ç®—æ€§èƒ½æµ‹è¯•")
    
    results = {}
    
    for batch_size in batch_sizes:
        print(f"\næµ‹è¯•æ‰¹æ¬¡å¤§å°: {batch_size}")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        x = tf.random.normal((batch_size, 100))
        
        # åˆ›å»ºç®€å•çš„ç¥ç»ç½‘ç»œ
        model = tf.keras.Sequential([
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dense(32, activation='relu'),
            tf.keras.layers.Dense(1)
        ])
        
        model.build(input_shape=(None, 100))
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        start_time = time.time()
        iterations = 0
        
        while time.time() - start_time < duration:
            _ = model(x)
            iterations += 1
        
        elapsed = time.time() - start_time
        ops_per_sec = iterations / elapsed
        
        results[batch_size] = {
            'iterations': iterations,
            'ops_per_sec': ops_per_sec,
            'elapsed': elapsed
        }
        
        print(f"   è¿­ä»£æ¬¡æ•°: {iterations}")
        print(f"   æ¯ç§’æ“ä½œæ•°: {ops_per_sec:.2f}")
    
    print(f"\nğŸ“Š TensorFlowæ€§èƒ½æµ‹è¯•ç»“æœ:")
    for batch_size, result in results.items():
        print(f"æ‰¹æ¬¡å¤§å° {batch_size}: {result['ops_per_sec']:.2f} ops/sec")
    
    return results


def diagnose_cpu_bottleneck():
    """
    è¯Šæ–­CPUç“¶é¢ˆ
    """
    print(f"ğŸ” å¼€å§‹CPUç“¶é¢ˆè¯Šæ–­...")
    
    try:
        import psutil
        
        # ç³»ç»Ÿä¿¡æ¯
        print(f"\nğŸ’» ç³»ç»Ÿä¿¡æ¯:")
        print(f"CPUæ ¸å¿ƒæ•°: {psutil.cpu_count(logical=False)} ç‰©ç†, {psutil.cpu_count(logical=True)} é€»è¾‘")
        
        memory = psutil.virtual_memory()
        print(f"å†…å­˜: {memory.total / (1024**3):.1f}GB æ€»é‡, {memory.available / (1024**3):.1f}GB å¯ç”¨")
        
        # CPUä½¿ç”¨ç‡åˆ†å¸ƒ
        print(f"\nğŸ“ˆ å½“å‰CPUçŠ¶æ€:")
        cpu_percent = psutil.cpu_percent(interval=1, percpu=True)
        for i, usage in enumerate(cpu_percent):
            print(f"CPU{i}: {usage:.1f}%")
        
        avg_usage = sum(cpu_percent) / len(cpu_percent)
        print(f"å¹³å‡ä½¿ç”¨ç‡: {avg_usage:.1f}%")
        
        # è¿›ç¨‹ä¿¡æ¯
        print(f"\nâš¡ è¿›ç¨‹ä¿¡æ¯:")
        current_process = psutil.Process()
        print(f"å½“å‰è¿›ç¨‹CPUä½¿ç”¨ç‡: {current_process.cpu_percent()}%")
        print(f"å½“å‰è¿›ç¨‹å†…å­˜ä½¿ç”¨: {current_process.memory_info().rss / (1024**2):.1f}MB")
        print(f"å½“å‰è¿›ç¨‹çº¿ç¨‹æ•°: {current_process.num_threads()}")
        
        # I/Oç»Ÿè®¡
        io_counters = current_process.io_counters()
        print(f"è¯»å–å­—èŠ‚æ•°: {io_counters.read_bytes / (1024**2):.1f}MB")
        print(f"å†™å…¥å­—èŠ‚æ•°: {io_counters.write_bytes / (1024**2):.1f}MB")
        
        # å»ºè®®
        print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        if avg_usage < 50:
            print("   - CPUä½¿ç”¨ç‡è¾ƒä½ï¼Œå¯èƒ½çš„åŸå› ï¼š")
            print("     * æ•°æ®I/Oæˆä¸ºç“¶é¢ˆ")
            print("     * å†…å­˜å¸¦å®½é™åˆ¶")
            print("     * TensorFlowé…ç½®ä¸å½“")
            print("     * æ‰¹æ¬¡å¤§å°è¿‡å°")
        
        if memory.percent > 80:
            print("   - å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå¯èƒ½å½±å“æ€§èƒ½")
        
        # ç¯å¢ƒå˜é‡æ£€æŸ¥
        print(f"\nğŸ”§ TensorFlowç¯å¢ƒå˜é‡:")
        tf_vars = [
            'TF_NUM_INTEROP_THREADS',
            'TF_NUM_INTRAOP_THREADS', 
            'OMP_NUM_THREADS',
            'MKL_NUM_THREADS',
            'TF_ENABLE_ONEDNN_OPTS'
        ]
        
        for var in tf_vars:
            value = os.environ.get(var, 'Not set')
            print(f"   {var}: {value}")
            
    except ImportError:
        print("æœªå®‰è£…psutilï¼Œæ— æ³•è¿›è¡Œè¯¦ç»†è¯Šæ–­")


def comprehensive_performance_test():
    """
    ç»¼åˆæ€§èƒ½æµ‹è¯•
    """
    print("ğŸš€ å¼€å§‹ç»¼åˆæ€§èƒ½æµ‹è¯•...")
    
    # 1. åŸºç¡€CPUæµ‹è¯•
    print("\n1ï¸âƒ£ åŸºç¡€CPUå‹åŠ›æµ‹è¯•")
    cpu_intensive_test(duration=15)
    
    # 2. TensorFlowè®¡ç®—æµ‹è¯•
    print("\n2ï¸âƒ£ TensorFlowè®¡ç®—æµ‹è¯•")
    tensorflow_compute_test(batch_sizes=[32, 128, 256], duration=30)
    
    # 3. ç³»ç»Ÿè¯Šæ–­
    print("\n3ï¸âƒ£ ç³»ç»Ÿç“¶é¢ˆè¯Šæ–­")
    diagnose_cpu_bottleneck()
    
    print("\nâœ… ç»¼åˆæ€§èƒ½æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    comprehensive_performance_test()