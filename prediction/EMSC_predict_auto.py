#!/usr/bin/env python3
"""
EMSCè‡ªåŠ¨å‚æ•°é¢„æµ‹è„šæœ¬
è‡ªåŠ¨ä»æ¨¡å‹å’Œé…ç½®æ–‡ä»¶ä¸­æ¨æ–­å¿…è¦çš„å‚æ•°
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import joblib
import os
import json
import sys
import argparse
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.EMSC_model import MSC_Sequence
from core.EMSC_losses import EMSCLoss, MaskedMSELoss
from matplotlib.gridspec import GridSpec

def auto_load_model_and_config(model_path):
    """
    è‡ªåŠ¨åŠ è½½æ¨¡å‹å¹¶æ¨æ–­æ‰€æœ‰å¿…è¦å‚æ•°
    
    Args:
        model_path: æ¨¡å‹è·¯å¾„ï¼ˆå¯ä»¥æ˜¯æ–‡ä»¶å¤¹æˆ–.h5æ–‡ä»¶ï¼‰
    
    Returns:
        dict: åŒ…å«æ¨¡å‹ã€æ ‡å‡†åŒ–å™¨å’Œå‚æ•°çš„å­—å…¸
    """
    result = {
        'model': None,
        'x_scaler': None, 
        'y_scaler': None,
        'state_dim': 8,      # é»˜è®¤å€¼
        'input_dim': 6,      # é»˜è®¤å€¼
        'window_size': 5000, # é»˜è®¤å€¼
        'network_structure': None
    }
    
    print(f"ğŸ” è‡ªåŠ¨åŠ è½½æ¨¡å‹: {model_path}")
    
    # 1. ç¡®å®šæ¨¡å‹ç›®å½•å’Œæ–‡ä»¶
    if os.path.isfile(model_path):
        # å¦‚æœæ˜¯æ–‡ä»¶ï¼ˆå¦‚.h5ï¼‰ï¼Œåˆ™çˆ¶ç›®å½•æ˜¯æ¨¡å‹ç›®å½•
        model_dir = os.path.dirname(model_path)
        model_file = model_path
    else:
        # å¦‚æœæ˜¯ç›®å½•ï¼Œåˆ™éœ€è¦åˆ¤æ–­æ˜¯SavedModelç›®å½•è¿˜æ˜¯åŒ…å«æ¨¡å‹çš„ç›®å½•
        if os.path.isdir(model_path):
            # æ£€æŸ¥æ˜¯å¦æ˜¯SavedModelç›®å½•ï¼ˆåŒ…å«saved_model.pbï¼‰
            saved_model_pb = os.path.join(model_path, 'saved_model.pb')
            if os.path.exists(saved_model_pb):
                # è¿™æ˜¯SavedModelç›®å½•
                model_dir = os.path.dirname(model_path)
                model_file = model_path
            else:
                # è¿™æ˜¯åŒ…å«æ¨¡å‹çš„ç›®å½•ï¼ŒæŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶/ç›®å½•
                model_dir = model_path
                possible_models = [
                    os.path.join(model_dir, 'best_msc_model'),
                    os.path.join(model_dir, 'msc_model'),
                    os.path.join(model_dir, 'best_msc_model.h5'),
                    os.path.join(model_dir, 'msc_model.h5')
                ]
                model_file = None
                for candidate in possible_models:
                    if os.path.exists(candidate):
                        model_file = candidate
                        break
                
                if model_file is None:
                    raise FileNotFoundError(f"åœ¨ {model_dir} ä¸­æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
        else:
            raise FileNotFoundError(f"è·¯å¾„ä¸å­˜åœ¨: {model_path}")
    
    print(f"ğŸ“ æ¨¡å‹ç›®å½•: {model_dir}")
    print(f"ğŸ“„ æ¨¡å‹æ–‡ä»¶: {os.path.basename(model_file)}")
    
    # 2. ä»ç›®å½•ç»“æ„æ¨æ–­ç½‘ç»œå‚æ•°
    parent_dir = os.path.basename(model_dir)
    if parent_dir.startswith('network_'):
        # è§£æç½‘ç»œç»“æ„ ä¾‹å¦‚: network_6-32-32-8-1
        structure = parent_dir.replace('network_', '')
        parts = structure.split('-')
        if len(parts) == 5:
            input_layer, hidden1, hidden2, state_dim, output_layer = map(int, parts)
            result['state_dim'] = state_dim
            result['input_dim'] = input_layer
            result['network_structure'] = structure
            print(f"ğŸ—ï¸  ä»æ–‡ä»¶å¤¹åæ¨æ–­ç½‘ç»œç»“æ„: {structure}")
            print(f"   state_dim: {state_dim}, input_dim: {input_layer}")
    
    # 3. å°è¯•åŠ è½½é…ç½®æ–‡ä»¶
    config_file = os.path.join(model_dir, 'training_config.json')
    if os.path.exists(config_file):
        try:
            with open(config_file, 'r') as f:
                config = json.load(f)
            
            # ä»é…ç½®æ–‡ä»¶æ›´æ–°å‚æ•°
            if 'STATE_DIM' in config:
                result['state_dim'] = config['STATE_DIM']
            if 'INPUT_DIM' in config:
                result['input_dim'] = config['INPUT_DIM']
                
            
            print(f"ğŸ“‹ ä»é…ç½®æ–‡ä»¶åŠ è½½å‚æ•°:")
            print(f"   state_dim: {result['state_dim']}")
            print(f"   input_dim: {result['input_dim']}")
            print(f"   window_size: {result['window_size']} (ä½¿ç”¨é»˜è®¤å€¼)")
                
        except Exception as e:
            print(f"âš ï¸  é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
    
    # 4. åŠ è½½æ¨¡å‹
    try:
        with tf.keras.utils.custom_object_scope({
            'MSC_Sequence': MSC_Sequence,
            'EMSCLoss': EMSCLoss,
            'MaskedMSELoss': MaskedMSELoss
        }):
            result['model'] = tf.keras.models.load_model(
                model_file,
                custom_objects={
                    'MSC_Sequence': MSC_Sequence,
                    'EMSCLoss': EMSCLoss,
                    'MaskedMSELoss': MaskedMSELoss
                }
            )
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # 5. ä»æ¨¡å‹ç»“æ„éªŒè¯/æ¨æ–­å‚æ•°
        try:
            # è·å–æ¨¡å‹è¾“å…¥å½¢çŠ¶
            input_shapes = [layer.input_shape for layer in result['model'].layers if hasattr(layer, 'input_shape')]
            
            # æŸ¥æ‰¾init_stateè¾“å…¥æ¥æ¨æ–­state_dim
            for layer in result['model'].layers:
                if hasattr(layer, 'input_shape') and isinstance(layer.input_shape, list):
                    for shape in layer.input_shape:
                        if shape and len(shape) == 2 and shape[1] is not None:
                            # è¿™å¯èƒ½æ˜¯init_stateçš„å½¢çŠ¶ [batch_size, state_dim]
                            inferred_state_dim = shape[1]
                            if inferred_state_dim != result['state_dim']:
                                print(f"ğŸ”„ ä»æ¨¡å‹ç»“æ„ä¿®æ­£state_dim: {result['state_dim']} -> {inferred_state_dim}")
                                result['state_dim'] = inferred_state_dim
                            break
            
            print(f"ğŸ—ï¸  æœ€ç»ˆæ¨¡å‹å‚æ•°:")
            print(f"   state_dim: {result['state_dim']}")
            print(f"   input_dim: {result['input_dim']}")
            
        except Exception as e:
            print(f"âš ï¸  æ¨¡å‹ç»“æ„åˆ†æå¤±è´¥: {e}")
            
    except Exception as e:
        raise RuntimeError(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    # 6. åŠ è½½æ ‡å‡†åŒ–å™¨
    scaler_locations = [
        model_dir,  # æ¨¡å‹åŒç›®å½•
        os.path.join(os.path.dirname(model_dir), 'scalers'),  # scalerså­ç›®å½•
        os.path.join(model_dir, 'scalers'),  # æ¨¡å‹ç›®å½•ä¸‹çš„scalers
    ]
    
    for scaler_dir in scaler_locations:
        x_scaler_path = os.path.join(scaler_dir, 'x_scaler.save')
        y_scaler_path = os.path.join(scaler_dir, 'y_scaler.save')
        
        if os.path.exists(x_scaler_path) and os.path.exists(y_scaler_path):
            try:
                result['x_scaler'] = joblib.load(x_scaler_path)
                result['y_scaler'] = joblib.load(y_scaler_path)
                print(f"âœ… æ ‡å‡†åŒ–å™¨åŠ è½½æˆåŠŸ: {scaler_dir}")
                break
            except Exception as e:
                print(f"âš ï¸  æ ‡å‡†åŒ–å™¨åŠ è½½å¤±è´¥ {scaler_dir}: {e}")
                continue
    
    if result['x_scaler'] is None or result['y_scaler'] is None:
        print("âŒ æœªæ‰¾åˆ°æ ‡å‡†åŒ–å™¨æ–‡ä»¶ï¼Œé¢„æµ‹å¯èƒ½ä¸å‡†ç¡®")
        print("ğŸ’¡ å»ºè®®æ£€æŸ¥ä»¥ä¸‹ä½ç½®çš„æ ‡å‡†åŒ–å™¨æ–‡ä»¶:")
        for loc in scaler_locations:
            print(f"   - {loc}/x_scaler.save")
            print(f"   - {loc}/y_scaler.save")
    
    return result

def smart_predict(model_info, strain_sequence, temperature, time_sequence=None):
    """
    æ™ºèƒ½é¢„æµ‹å‡½æ•°ï¼Œè‡ªåŠ¨ä½¿ç”¨æ¨æ–­çš„å‚æ•°
    
    Args:
        model_info: auto_load_model_and_configè¿”å›çš„ä¿¡æ¯å­—å…¸
        strain_sequence: åº”å˜åºåˆ—
        temperature: æ¸©åº¦
        time_sequence: æ—¶é—´åºåˆ—ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        predicted_stress: é¢„æµ‹åº”åŠ›
        time_sequence: æ—¶é—´åºåˆ—
    """
    print(f"ğŸš€ å¼€å§‹é¢„æµ‹ (åºåˆ—é•¿åº¦: {len(strain_sequence)})")
    print(f"ğŸŒ¡ï¸  æ¸©åº¦: {temperature}Â°C")
    print(f"ğŸ“ ä½¿ç”¨å‚æ•°: state_dim={model_info['state_dim']}, input_dim={model_info['input_dim']}, window_size={model_info['window_size']}")
    
    if model_info['x_scaler'] is None or model_info['y_scaler'] is None:
        raise ValueError("ç¼ºå°‘æ ‡å‡†åŒ–å™¨ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹")
    
    # ä½¿ç”¨å·²æœ‰çš„é¢„æµ‹å‡½æ•°
    from prediction.EMSC_predict import predict_stress
    
    return predict_stress(
        model=model_info['model'],
        x_scaler=model_info['x_scaler'],
        y_scaler=model_info['y_scaler'],
        strain_sequence=strain_sequence,
        temperature=temperature,
        time_sequence=time_sequence,
        state_dim=model_info['state_dim'],
        input_dim=model_info['input_dim'],
        window_size=model_info['window_size']
    )

def find_best_model():
    """
    è‡ªåŠ¨å¯»æ‰¾æœ€ä½³è®­ç»ƒæ¨¡å‹
    
    Returns:
        str: æœ€ä½³æ¨¡å‹çš„è·¯å¾„
    """
    base_paths = [
        '/Users/tianyunhu/Documents/temp/code/Test_app/EMSC_Model/msc_models/dataset_EMSC_big',
        'models/dataset_EMSC_big',
        '../models/dataset_EMSC_big'
    ]
    
    best_models = []
    
    for base_path in base_paths:
        if not os.path.exists(base_path):
            continue
            
        print(f"ğŸ” æœç´¢æ¨¡å‹: {base_path}")
        
        # æŸ¥æ‰¾æ‰€æœ‰ç½‘ç»œæ–‡ä»¶å¤¹
        for item in os.listdir(base_path):
            if item.startswith('network_'):
                model_dir = os.path.join(base_path, item)
                if os.path.isdir(model_dir):
                    # æ£€æŸ¥æ˜¯å¦æœ‰bestæ¨¡å‹
                    best_model_path = os.path.join(model_dir, 'best_msc_model')
                    if os.path.exists(best_model_path):
                        best_models.append({
                            'path': best_model_path,
                            'structure': item.replace('network_', ''),
                            'dir': model_dir
                        })
                        print(f"  âœ… æ‰¾åˆ°: {item}")
    
    if not best_models:
        raise FileNotFoundError("æœªæ‰¾åˆ°ä»»ä½•è®­ç»ƒå¥½çš„æ¨¡å‹")
    
    # æŒ‰ç½‘ç»œç»“æ„æ’åºï¼Œé€‰æ‹©æ ‡å‡†é…ç½®æˆ–æœ€å¤§çš„ç½‘ç»œ
    best_models.sort(key=lambda x: x['structure'])
    
    # ä¼˜å…ˆé€‰æ‹©æ ‡å‡†é…ç½® 6-32-32-8-1
    for model in best_models:
        if model['structure'] == '6-8-8-8-1':
            print(f"ğŸ¯ é€‰æ‹©æ ‡å‡†é…ç½®: {model['structure']}")
            return model['path']
    
    # å¦åˆ™é€‰æ‹©ç¬¬ä¸€ä¸ª
    selected = best_models[0]
    print(f"ğŸ¯ é€‰æ‹©æ¨¡å‹: {selected['structure']}")
    return selected['path']

def plot_combined_results(all_results):
    """
    å°†æ‰€æœ‰é¢„æµ‹ç»“æœç»˜åˆ¶åœ¨åŒä¸€ä¸ªå›¾ä¸Š
    
    Args:
        all_results: åŒ…å«æ‰€æœ‰é¢„æµ‹ç»“æœçš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«ï¼š
            - strain_sequence: åº”å˜åºåˆ—
            - predicted_stress: é¢„æµ‹åº”åŠ›
            - exp_strain: å®éªŒåº”å˜
            - exp_stress: å®éªŒåº”åŠ›
            - temperature: æ¸©åº¦
            - filename: æ–‡ä»¶å
            - error_metrics: è¯¯å·®æŒ‡æ ‡
    """
    plt.style.use('seaborn')
    fig = plt.figure(figsize=(8, 6))
    gs = GridSpec(2, 1, height_ratios=[3, 1])
    
    # ä¸»å›¾ï¼šåº”åŠ›-åº”å˜æ›²çº¿
    ax1 = fig.add_subplot(gs[0])
    ax1.set_title('EMSCé¢„æµ‹ç»“æœå¯¹æ¯”', fontsize=14, pad=15)
    ax1.set_xlabel('åº”å˜', fontsize=12)
    ax1.set_ylabel('åº”åŠ› (MPa)', fontsize=12)
    
    # ä½¿ç”¨ä¸åŒçš„é¢œè‰²å’Œæ ‡è®°æ ·å¼
    colors = plt.cm.tab10(np.linspace(0, 1, len(all_results)))
    markers = ['o', 's', '^', 'D', 'v', '<', '>', 'p', '*', 'h']
    
    # ç»˜åˆ¶æ¯ä¸ªæ–‡ä»¶çš„ç»“æœ
    for i, result in enumerate(all_results):
        color = colors[i]
        marker = markers[i % len(markers)]
        label = f"{os.path.basename(result['filename'])} (T={result['temperature']}Â°C)"
        
        # ç»˜åˆ¶å®éªŒæ•°æ®
        ax1.plot(result['exp_strain'], result['exp_stress'], 
                color=color, marker=marker, markersize=4, linestyle='',
                label=f"{label} (å®éªŒ)")
        
        # ç»˜åˆ¶é¢„æµ‹æ•°æ®
        ax1.plot(result['strain_sequence'], result['predicted_stress'],
                color=color, linestyle='-', linewidth=1.5,
                label=f"{label} (é¢„æµ‹)")
    
    ax1.grid(True, linestyle='--', alpha=0.7)
    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)
    
    # è¯¯å·®æŒ‡æ ‡è¡¨æ ¼
    ax2 = fig.add_subplot(gs[1])
    ax2.axis('off')
    
    # å‡†å¤‡è¡¨æ ¼æ•°æ®
    table_data = []
    headers = ['æ–‡ä»¶å', 'æ¸©åº¦(Â°C)', 'RÂ²', 'RMSE(MPa)', 'MAE(MPa)']
    
    for result in all_results:
        metrics = result['error_metrics']
        table_data.append([
            os.path.basename(result['filename']),
            f"{result['temperature']:.1f}",
            f"{metrics['R2']:.4f}",
            f"{metrics['RMSE']:.2f}",
            f"{metrics['MAE']:.2f}"
        ])
    
    # è®¡ç®—å¹³å‡å€¼
    avg_metrics = {
        'R2': np.mean([r['error_metrics']['R2'] for r in all_results]),
        'RMSE': np.mean([r['error_metrics']['RMSE'] for r in all_results]),
        'MAE': np.mean([r['error_metrics']['MAE'] for r in all_results])
    }
    
    # æ·»åŠ å¹³å‡å€¼è¡Œ
    table_data.append([
        'å¹³å‡å€¼',
        '-',
        f"{avg_metrics['R2']:.4f}",
        f"{avg_metrics['RMSE']:.2f}",
        f"{avg_metrics['MAE']:.2f}"
    ])
    
    # åˆ›å»ºè¡¨æ ¼
    table = ax2.table(
        cellText=table_data,
        colLabels=headers,
        loc='center',
        cellLoc='center',
        colWidths=[0.3, 0.15, 0.15, 0.15, 0.15]
    )
    
    # è®¾ç½®è¡¨æ ¼æ ·å¼
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1.2, 1.5)
    
    # è®¾ç½®è¡¨æ ¼æ ‡é¢˜
    ax2.set_title('é¢„æµ‹ç»“æœç»Ÿè®¡', pad=20, fontsize=12)
    
    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    save_path = 'combined_predictions.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"\nğŸ’¾ ç»„åˆé¢„æµ‹å›¾å·²ä¿å­˜è‡³: {save_path}")
    
    plt.show()

def main():
    """ä¸»å‡½æ•° - ç®€åŒ–çš„ä½¿ç”¨æ¥å£"""
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='EMSCè‡ªåŠ¨é¢„æµ‹è„šæœ¬')
    parser.add_argument('-n', '--num_files', type=int, default=1,
                      help='è¦éšæœºé€‰æ‹©çš„æ–‡ä»¶æ•°é‡ (é»˜è®¤: 1)')
    parser.add_argument('-g', '--gap', type=int, default=1,
                      help='å®éªŒæ•°æ®é—´éš” (é»˜è®¤: 1)')   
    args = parser.parse_args()
    
    # 1. è‡ªåŠ¨æ‰¾åˆ°æœ€ä½³æ¨¡å‹
    try:
        model_path = find_best_model()
    except Exception as e:
        print(f"âŒ {e}")
        print("ğŸ’¡ è¯·æ‰‹åŠ¨æŒ‡å®šæ¨¡å‹è·¯å¾„")
        return
    
    # 2. è‡ªåŠ¨åŠ è½½æ¨¡å‹å’Œé…ç½®
    try:
        model_info = auto_load_model_and_config(model_path)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    print(f"\n{'='*50}")
    print(f"ğŸ‰ æ¨¡å‹åŠ è½½å®Œæˆ!")
    if model_info['network_structure']:
        print(f"ğŸ“Š ç½‘ç»œç»“æ„: {model_info['network_structure']}")
    print(f"ğŸ“ æ¨¡å‹å‚æ•°: state_dim={model_info['state_dim']}, input_dim={model_info['input_dim']}")
    print(f"ğŸªŸ çª—å£å¤§å°: {model_info['window_size']}")
    print(f"{'='*50}\n")
    
    # 3. åŠ è½½å®éªŒæ•°æ®
    file_path = '/Users/tianyunhu/Documents/temp/CTC/PPCC/'
    import glob
    file_list = glob.glob(os.path.join(file_path, "*.xlsx"))
    
    if not file_list:
        print("âŒ æœªæ‰¾åˆ°å®éªŒæ•°æ®æ–‡ä»¶")
        return
    
    # ç¡®ä¿nä¸è¶…è¿‡å¯ç”¨æ–‡ä»¶æ•°é‡
    n_files = min(args.num_files, len(file_list))
    if n_files < args.num_files:
        print(f"âš ï¸ è­¦å‘Š: è¯·æ±‚çš„æ–‡ä»¶æ•°é‡({args.num_files})è¶…è¿‡å¯ç”¨æ–‡ä»¶æ•°é‡({len(file_list)})")
        print(f"   å°†ä½¿ç”¨æ‰€æœ‰å¯ç”¨æ–‡ä»¶({n_files}ä¸ª)")
    
    # éšæœºé€‰æ‹©nä¸ªæ–‡ä»¶
    selected_files = np.random.choice(file_list, size=n_files, replace=False)

    # selected_files = ['/Users/tianyunhu/Documents/temp/CTC/PPCC/PPCC_Ten_263.636_40.102.xlsx']
    # gap = 100

    print(f"ğŸ“ å·²é€‰æ‹© {n_files} ä¸ªæµ‹è¯•æ–‡ä»¶:")
    for i, file in enumerate(selected_files, 1):
        print(f"  {i}. {os.path.basename(file)}")
    
    from prediction.EMSC_predict import load_experimental_data, calculate_error_metrics, plot_results
    
    # å­˜å‚¨æ‰€æœ‰ç»“æœ
    all_results = []
    
    for selected_file in selected_files:
        print(f"\n{'='*50}")
        print(f"ğŸ“Š å¤„ç†æ–‡ä»¶: {os.path.basename(selected_file)}")
        
        exp_strain, exp_stress, exp_time, temperature = load_experimental_data(selected_file, gap = args.gap)
        
        if exp_strain is None:
            print(f"âŒ æ–‡ä»¶ {os.path.basename(selected_file)} æ•°æ®åŠ è½½å¤±è´¥ï¼Œè·³è¿‡")
            continue
        
        # è¿›è¡Œé¢„æµ‹
        try:
            predicted_stress, time_sequence = smart_predict(
                model_info=model_info,
                strain_sequence=exp_strain,
                temperature=temperature,
                time_sequence=exp_time
            )
            
            print("âœ… é¢„æµ‹å®Œæˆ!")
            
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            continue
        
        # è®¡ç®—è¯¯å·®
        error_metrics = calculate_error_metrics(
            predicted_stress, exp_strain, exp_stress, exp_strain
        )
        
        # å­˜å‚¨ç»“æœ
        all_results.append({
            'strain_sequence': exp_strain,
            'predicted_stress': predicted_stress,
            'exp_strain': exp_strain,
            'exp_stress': exp_stress,
            'temperature': temperature,
            'filename': selected_file,
            'error_metrics': error_metrics
        })
        
        print(f"\nğŸ¯ æ–‡ä»¶ {os.path.basename(selected_file)} é¢„æµ‹ç»“æœ:")
        print(f"   RÂ²: {error_metrics['R2']:.4f}")
        print(f"   RMSE: {error_metrics['RMSE']:.2f} MPa")
        print(f"   MAE: {error_metrics['MAE']:.2f} MPa")
    
    # å¦‚æœæœ‰ç»“æœï¼Œç»˜åˆ¶ç»„åˆå›¾
    if all_results:
        print("\nğŸ“Š æ­£åœ¨ç”Ÿæˆç»„åˆé¢„æµ‹å›¾...")
        plot_combined_results(all_results)
        
        # è®¡ç®—å¹¶æ˜¾ç¤ºå¹³å‡ç»“æœ
        avg_metrics = {
            'R2': np.mean([r['error_metrics']['R2'] for r in all_results]),
            'RMSE': np.mean([r['error_metrics']['RMSE'] for r in all_results]),
            'MAE': np.mean([r['error_metrics']['MAE'] for r in all_results])
        }
        
        print(f"\n{'='*50}")
        print(f"ğŸ“Š {len(all_results)}ä¸ªæ–‡ä»¶çš„å¹³å‡é¢„æµ‹ç»“æœ:")
        print(f"   RÂ²: {avg_metrics['R2']:.4f}")
        print(f"   RMSE: {avg_metrics['RMSE']:.2f} MPa")
        print(f"   MAE: {avg_metrics['MAE']:.2f} MPa")
        print(f"{'='*50}")
    else:
        print("\nâŒ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ–‡ä»¶")

if __name__ == '__main__':
    main() 