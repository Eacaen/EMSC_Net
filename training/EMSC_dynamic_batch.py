"""
åŠ¨æ€æ‰¹æ¬¡å¤§å°è°ƒæ•´æ¨¡å—
æ ¹æ®CPUä½¿ç”¨ç‡è‡ªåŠ¨è°ƒæ•´æ‰¹æ¬¡å¤§å°ä»¥ä¼˜åŒ–èµ„æºåˆ©ç”¨ç‡
"""

import threading
import time
import numpy as np
import tensorflow as tf
import sys
import os
from typing import Optional, Callable
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


class DynamicBatchSizeCallback(tf.keras.callbacks.Callback):
    """åŠ¨æ€æ‰¹æ¬¡å¤§å°è°ƒæ•´å›è°ƒ"""
    
    def __init__(self, 
                 target_cpu_usage=75.0,  # ç›®æ ‡CPUä½¿ç”¨ç‡
                 tolerance=10.0,         # å®¹å¿åº¦
                 min_batch_size=16,      # æœ€å°æ‰¹æ¬¡å¤§å°
                 max_batch_size=512,     # æœ€å¤§æ‰¹æ¬¡å¤§å°
                 adjustment_factor=1.5,  # è°ƒæ•´å› å­ï¼ˆæ›´æ¿€è¿›ï¼‰
                 monitor_interval=15,    # ç›‘æ§é—´éš”ï¼ˆç§’ï¼‰- æ›´é¢‘ç¹
                 patience=1,             # è¿ç»­å¤šå°‘ä¸ªepochæ‰è°ƒæ•´ - æ›´å¿«å“åº”
                 verbose=True):
        """
        Args:
            target_cpu_usage: ç›®æ ‡CPUä½¿ç”¨ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
            tolerance: CPUä½¿ç”¨ç‡å®¹å¿åº¦
            min_batch_size: æœ€å°æ‰¹æ¬¡å¤§å°
            max_batch_size: æœ€å¤§æ‰¹æ¬¡å¤§å°
            adjustment_factor: æ‰¹æ¬¡å¤§å°è°ƒæ•´å› å­
            monitor_interval: CPUç›‘æ§é—´éš”
            patience: è¿ç»­å¤šå°‘ä¸ªepochä½¿ç”¨ç‡ä¸è¾¾æ ‡æ‰è°ƒæ•´
            verbose: æ˜¯å¦æ‰“å°è°ƒæ•´ä¿¡æ¯
        """
        super().__init__()
        self.target_cpu_usage = target_cpu_usage
        self.tolerance = tolerance
        self.min_batch_size = min_batch_size
        self.max_batch_size = max_batch_size
        self.adjustment_factor = adjustment_factor
        self.monitor_interval = monitor_interval
        self.patience = patience
        self.verbose = verbose
        
        # çŠ¶æ€å˜é‡
        self.current_batch_size = None
        self.cpu_usage_history = []
        self.low_usage_count = 0
        self.high_usage_count = 0
        self.monitoring = False
        self.monitor_thread = None
        self.latest_cpu_usage = 0.0
        
        # æ•°æ®é‡å»ºå›è°ƒ
        self.dataset_rebuilder = None
        
    def set_dataset_rebuilder(self, rebuilder_func: Callable):
        """è®¾ç½®æ•°æ®é›†é‡å»ºå‡½æ•°"""
        self.dataset_rebuilder = rebuilder_func
    
    def on_train_begin(self, logs=None):
        """è®­ç»ƒå¼€å§‹æ—¶å¯åŠ¨CPUç›‘æ§"""
        try:
            import psutil
            self.psutil = psutil
            self.monitoring = True
            self.monitor_thread = threading.Thread(target=self._monitor_cpu)
            self.monitor_thread.daemon = True
            self.monitor_thread.start()
            if self.verbose:
                print(f"å¯åŠ¨åŠ¨æ€æ‰¹æ¬¡å¤§å°è°ƒæ•´ (ç›®æ ‡CPUä½¿ç”¨ç‡: {self.target_cpu_usage}%)")
        except ImportError:
            if self.verbose:
                print("è­¦å‘Š: æœªå®‰è£…psutilï¼Œæ— æ³•è¿›è¡ŒåŠ¨æ€æ‰¹æ¬¡å¤§å°è°ƒæ•´")
    
    def on_train_end(self, logs=None):
        """è®­ç»ƒç»“æŸæ—¶åœæ­¢ç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5)
        if self.verbose:
            print("åœæ­¢åŠ¨æ€æ‰¹æ¬¡å¤§å°è°ƒæ•´")
    
    def on_epoch_begin(self, epoch, logs=None):
        """è®°å½•å½“å‰epochçš„æ‰¹æ¬¡å¤§å°"""
        if hasattr(self.model, 'current_batch_size'):
            self.current_batch_size = self.model.current_batch_size
        if self.verbose and epoch == 0:
            print(f"åˆå§‹æ‰¹æ¬¡å¤§å°: {self.current_batch_size}")
    
    def on_epoch_end(self, epoch, logs=None):
        """åœ¨epochç»“æŸæ—¶å†³å®šæ˜¯å¦è°ƒæ•´æ‰¹æ¬¡å¤§å°"""
        if not self.cpu_usage_history:
            return
        
        # è®¡ç®—æœ€è¿‘å‡ æ¬¡çš„å¹³å‡CPUä½¿ç”¨ç‡
        recent_usage = np.mean(self.cpu_usage_history[-3:]) if len(self.cpu_usage_history) >= 3 else self.latest_cpu_usage
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒæ•´
        if recent_usage < self.target_cpu_usage - self.tolerance:
            self.low_usage_count += 1
            self.high_usage_count = 0
        elif recent_usage > self.target_cpu_usage + self.tolerance:
            self.high_usage_count += 1
            self.low_usage_count = 0
        else:
            self.low_usage_count = 0
            self.high_usage_count = 0
        
        # è®¡ç®—CPUä½¿ç”¨ç‡å·®è·ï¼Œå†³å®šè°ƒæ•´å¹…åº¦
        cpu_gap = abs(recent_usage - self.target_cpu_usage)
        
        # æ ¹æ®å·®è·å†³å®šè°ƒæ•´å› å­ï¼ˆè¶…æ¿€è¿›çš„è°ƒæ•´ç­–ç•¥ï¼‰
        if cpu_gap > 30:
            dynamic_factor = 4.0  # å·®è·å¾ˆå¤§æ—¶ï¼Œè¶…æ¿€è¿›è°ƒæ•´
        elif cpu_gap > 20:
            dynamic_factor = 3.0
        elif cpu_gap > 10:
            dynamic_factor = 2.5
        else:
            dynamic_factor = 2.0
        
        # è¾¾åˆ°patienceæ‰è°ƒæ•´
        new_batch_size = self.current_batch_size
        adjustment_made = False
        
        if self.low_usage_count >= self.patience and self.current_batch_size < self.max_batch_size:
            # CPUä½¿ç”¨ç‡è¿‡ä½ï¼Œå¢åŠ æ‰¹æ¬¡å¤§å°
            new_batch_size = min(
                int(self.current_batch_size * dynamic_factor),
                self.max_batch_size
            )
            # ç¡®ä¿æ˜¯8çš„å€æ•°
            new_batch_size = (new_batch_size // 8) * 8
            adjustment_made = True
            self.low_usage_count = 0
            
        elif self.high_usage_count >= self.patience and self.current_batch_size > self.min_batch_size:
            # CPUä½¿ç”¨ç‡è¿‡é«˜ï¼Œå‡å°‘æ‰¹æ¬¡å¤§å°
            new_batch_size = max(
                int(self.current_batch_size / dynamic_factor),
                self.min_batch_size
            )
            # ç¡®ä¿æ˜¯8çš„å€æ•°
            new_batch_size = (new_batch_size // 8) * 8
            adjustment_made = True
            self.high_usage_count = 0
        
        if adjustment_made and new_batch_size != self.current_batch_size:
            if self.verbose:
                print(f"\nğŸ”„ åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°:")
                print(f"   å½“å‰CPUä½¿ç”¨ç‡: {recent_usage:.1f}%")
                print(f"   ç›®æ ‡CPUä½¿ç”¨ç‡: {self.target_cpu_usage}%")
                print(f"   ä½¿ç”¨ç‡å·®è·: {cpu_gap:.1f}%")
                print(f"   åŠ¨æ€è°ƒæ•´å› å­: {dynamic_factor:.1f}x")
                print(f"   æ‰¹æ¬¡å¤§å°: {self.current_batch_size} â†’ {new_batch_size}")
                
                # ç»™å‡ºè¿›ä¸€æ­¥çš„è¯Šæ–­å»ºè®®
                if cpu_gap > 30:
                    print(f"   ğŸ’¡ CPUä½¿ç”¨ç‡å·®è·å¾ˆå¤§ï¼Œå¯èƒ½å­˜åœ¨ä»¥ä¸‹ç“¶é¢ˆ:")
                    print(f"      - æ•°æ®I/Oç­‰å¾…æ—¶é—´è¿‡é•¿")
                    print(f"      - ç½‘ç»œå­˜å‚¨å»¶è¿Ÿ")
                    print(f"      - å†…å­˜å¸¦å®½é™åˆ¶")
                    print(f"      - TensorFlowçº¿ç¨‹é…ç½®ä¸å½“")
            
            # æ›´æ–°æ‰¹æ¬¡å¤§å°
            self.current_batch_size = new_batch_size
            
            # å¦‚æœæœ‰æ•°æ®é›†é‡å»ºå‡½æ•°ï¼Œè°ƒç”¨å®ƒ
            if self.dataset_rebuilder:
                try:
                    self.dataset_rebuilder(new_batch_size)
                    if self.verbose:
                        print(f"   âœ… æ•°æ®é›†å·²é‡å»ºä¸ºæ–°æ‰¹æ¬¡å¤§å°")
                except Exception as e:
                    if self.verbose:
                        print(f"   âŒ æ•°æ®é›†é‡å»ºå¤±è´¥: {e}")
        
        # å¢åŠ CPUä½¿ç”¨ç‡ç›‘æ§æ˜¾ç¤º
        elif self.verbose and epoch % 5 == 0:  # æ¯5ä¸ªepochæ˜¾ç¤ºä¸€æ¬¡çŠ¶æ€
            print(f"\nğŸ“Š CPUä½¿ç”¨ç‡çŠ¶æ€:")
            print(f"   å½“å‰: {recent_usage:.1f}% | ç›®æ ‡: {self.target_cpu_usage}% | æ‰¹æ¬¡: {self.current_batch_size}")
            if cpu_gap > 15:
                print(f"   âš ï¸  ä½¿ç”¨ç‡åå·®è¾ƒå¤§ ({cpu_gap:.1f}%)ï¼Œç»§ç»­ç›‘æ§...")
    
    def _monitor_cpu(self):
        """CPUç›‘æ§ä¸»å¾ªç¯"""
        while self.monitoring:
            try:
                # è·å–CPUä½¿ç”¨ç‡
                cpu_percent = self.psutil.cpu_percent(interval=1)
                
                # è®°å½•ä½¿ç”¨ç‡
                self.latest_cpu_usage = cpu_percent
                self.cpu_usage_history.append(cpu_percent)
                
                # ä¿æŒå†å²è®°å½•ä¸è¶…è¿‡20æ¡
                if len(self.cpu_usage_history) > 20:
                    self.cpu_usage_history.pop(0)
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
                time.sleep(self.monitor_interval)
                
            except Exception as e:
                if self.verbose:
                    print(f"CPUç›‘æ§å‡ºé”™: {e}")
                time.sleep(self.monitor_interval)


class DynamicBatchTrainer:
    """æ”¯æŒåŠ¨æ€æ‰¹æ¬¡å¤§å°çš„è®­ç»ƒå™¨"""
    
    def __init__(self, model, train_data_info, val_data_info, initial_batch_size=32):
        """
        Args:
            model: Kerasæ¨¡å‹
            train_data_info: è®­ç»ƒæ•°æ®ä¿¡æ¯ (X_train, Y_train, init_states_train)
            val_data_info: éªŒè¯æ•°æ®ä¿¡æ¯ (X_val, Y_val, init_states_val)
            initial_batch_size: åˆå§‹æ‰¹æ¬¡å¤§å°
        """
        self.model = model
        self.train_data_info = train_data_info
        self.val_data_info = val_data_info
        self.current_batch_size = initial_batch_size
        self.model.current_batch_size = initial_batch_size
        
        # æ•°æ®é›†
        self.train_dataset = None
        self.val_dataset = None
        self._rebuild_datasets()
    
    def _rebuild_datasets(self):
        """é‡å»ºæ•°æ®é›†"""
        from core.EMSC_data import create_tf_dataset
        
        X_train, Y_train, init_states_train = self.train_data_info
        X_val, Y_val, init_states_val = self.val_data_info
        
        # é‡å»ºè®­ç»ƒæ•°æ®é›†
        self.train_dataset = create_tf_dataset(
            X_train, Y_train, init_states_train,
            batch_size=self.current_batch_size,
            shuffle=True,
            num_parallel_calls=tf.data.AUTOTUNE
        ).prefetch(tf.data.AUTOTUNE)
        
        # é‡å»ºéªŒè¯æ•°æ®é›†
        self.val_dataset = create_tf_dataset(
            X_val, Y_val, init_states_val,
            batch_size=self.current_batch_size,
            shuffle=False,
            num_parallel_calls=tf.data.AUTOTUNE
        ).prefetch(tf.data.AUTOTUNE)
        
        # æ›´æ–°æ¨¡å‹çš„æ‰¹æ¬¡å¤§å°è®°å½•
        self.model.current_batch_size = self.current_batch_size
    
    def update_batch_size(self, new_batch_size):
        """æ›´æ–°æ‰¹æ¬¡å¤§å°å¹¶é‡å»ºæ•°æ®é›†"""
        if new_batch_size != self.current_batch_size:
            self.current_batch_size = new_batch_size
            self._rebuild_datasets()
    
    def fit(self, epochs, callbacks=None, **kwargs):
        """è®­ç»ƒæ¨¡å‹"""
        if callbacks is None:
            callbacks = []
        
        # æ·»åŠ åŠ¨æ€æ‰¹æ¬¡å¤§å°è°ƒæ•´å›è°ƒ
        dynamic_callback = DynamicBatchSizeCallback(verbose=True)
        dynamic_callback.set_dataset_rebuilder(self.update_batch_size)
        callbacks.append(dynamic_callback)
        
        return self.model.fit(
            self.train_dataset,
            validation_data=self.val_dataset,
            epochs=epochs,
            callbacks=callbacks,
            **kwargs
        )


def create_dynamic_batch_callback(target_cpu_usage=75.0, 
                                min_batch_size=16,
                                max_batch_size=512,
                                verbose=True):
    """
    åˆ›å»ºåŠ¨æ€æ‰¹æ¬¡å¤§å°è°ƒæ•´å›è°ƒ
    
    Args:
        target_cpu_usage: ç›®æ ‡CPUä½¿ç”¨ç‡
        min_batch_size: æœ€å°æ‰¹æ¬¡å¤§å°
        max_batch_size: æœ€å¤§æ‰¹æ¬¡å¤§å°
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    
    Returns:
        DynamicBatchSizeCallbackå®ä¾‹
    """
    return DynamicBatchSizeCallback(
        target_cpu_usage=target_cpu_usage,
        min_batch_size=min_batch_size,
        max_batch_size=max_batch_size,
        verbose=verbose
    )