"""
EMSCè®­ç»ƒè¯Šæ–­å·¥å…·
ç”¨äºåˆ†æè®­ç»ƒåœæ»å’ŒæŸå¤±åœæ»çš„å…·ä½“åŸå› 
"""

import os
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.metrics import r2_score
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.EMSC_model import build_msc_model
from core.EMSC_losses import EMSCLoss


class EMSCTrainingDiagnosis:
    """EMSCè®­ç»ƒè¯Šæ–­å™¨"""
    
    def __init__(self, model_path=None, dataset_path=None, state_dim=8, hidden_dim=32):
        self.model_path = model_path
        self.dataset_path = dataset_path
        self.state_dim = state_dim
        self.hidden_dim = hidden_dim
        self.model = None
        self.train_data = None
        self.val_data = None
        
    def load_model_and_data(self):
        """åŠ è½½æ¨¡å‹å’Œæ•°æ®"""
        print("ğŸ” åŠ è½½æ¨¡å‹å’Œæ•°æ®...")
        
        # åŠ è½½æ¨¡å‹
        if self.model_path and os.path.exists(self.model_path):
            try:
                from core.EMSC_model import MSC_Sequence
                from core.EMSC_losses import EMSCLoss
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯SavedModelç›®å½•æ ¼å¼
                if os.path.isdir(self.model_path):
                    # æŸ¥æ‰¾ç›®å½•ä¸­çš„æ¨¡å‹æ–‡ä»¶
                    possible_models = []
                    for item in os.listdir(self.model_path):
                        item_path = os.path.join(self.model_path, item)
                        if os.path.isdir(item_path):
                            # æ£€æŸ¥æ˜¯å¦æ˜¯SavedModelæ ¼å¼ç›®å½•
                            if os.path.exists(os.path.join(item_path, 'saved_model.pb')):
                                possible_models.append(item_path)
                        elif item.endswith('.h5') or item.endswith('.keras'):
                            possible_models.append(item_path)
                    
                    if possible_models:
                        # ä¼˜å…ˆé€‰æ‹©bestæ¨¡å‹
                        best_model = None
                        current_model = None
                        for model_path in possible_models:
                            if 'best' in os.path.basename(model_path).lower():
                                best_model = model_path
                            elif 'msc_model' in os.path.basename(model_path).lower():
                                current_model = model_path
                        
                        model_to_load = best_model or current_model or possible_models[0]
                        print(f"å‘ç°å¤šä¸ªæ¨¡å‹ï¼Œé€‰æ‹©: {os.path.basename(model_to_load)}")
                        self.model_path = model_to_load
                    else:
                        print(f"âŒ åœ¨ç›®å½• {self.model_path} ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ¨¡å‹æ–‡ä»¶")
                        return False
                
                # åŠ è½½æ¨¡å‹
                self.model = tf.keras.models.load_model(
                    self.model_path,
                    custom_objects={
                        'MSC_Sequence': MSC_Sequence,
                        'EMSCLoss': EMSCLoss
                    }
                )
                print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_path}")
                
            except Exception as e:
                print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                print("å°è¯•åˆ›å»ºæ–°æ¨¡å‹è¿›è¡Œåˆ†æ...")
                self.model = build_msc_model(
                    state_dim=self.state_dim,
                    hidden_dim=self.hidden_dim,
                    input_dim=6,
                    output_dim=1
                )
                print("âœ… å·²åˆ›å»ºæ–°æ¨¡å‹ç”¨äºåˆ†æ")
        else:
            print("âš ï¸  æœªæä¾›æ¨¡å‹è·¯å¾„æˆ–è·¯å¾„ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ¨¡å‹ç”¨äºåˆ†æ")
            self.model = build_msc_model(
                state_dim=self.state_dim,
                hidden_dim=self.hidden_dim,
                input_dim=6,
                output_dim=1
            )
            
        # åŠ è½½æ•°æ®
        if self.dataset_path and os.path.exists(self.dataset_path):
            try:
                # æ£€æŸ¥æ•°æ®é›†æ ¼å¼
                if self.dataset_path.endswith('.tfrecord'):
                    print(f"æ£€æµ‹åˆ°TFRecordæ ¼å¼æ•°æ®é›†: {self.dataset_path}")
                    # å¯¹äºTFRecordï¼Œæˆ‘ä»¬åªéœ€è¦ç¡®è®¤æ–‡ä»¶å­˜åœ¨å³å¯è¿›è¡Œåˆ†æ
                    print(f"âœ… TFRecordæ•°æ®é›†ç¡®è®¤å­˜åœ¨")
                    return True
                elif self.dataset_path.endswith('.npz'):
                    print(f"æ£€æµ‹åˆ°NPZæ ¼å¼æ•°æ®é›†: {self.dataset_path}")
                    from core.EMSC_data import load_dataset_smart
                    dataset_result = load_dataset_smart(self.dataset_path)
                    if dataset_result:
                        print(f"âœ… NPZæ•°æ®é›†åŠ è½½æˆåŠŸ")
                        return True
                    else:
                        print(f"âŒ NPZæ•°æ®é›†åŠ è½½å¤±è´¥")
                        return False
                else:
                    print(f"âš ï¸  æœªè¯†åˆ«çš„æ•°æ®é›†æ ¼å¼: {self.dataset_path}")
                    print("æ”¯æŒçš„æ ¼å¼: .tfrecord, .npz")
                    return False
                    
            except Exception as e:
                print(f"âŒ æ•°æ®é›†å¤„ç†å¤±è´¥: {e}")
                return False
        else:
            print("âš ï¸  æœªæä¾›æ•°æ®é›†è·¯å¾„æˆ–è·¯å¾„ä¸å­˜åœ¨")
            print("å°†ä»…ä½¿ç”¨æ¨¡å‹è¿›è¡Œåˆ†æï¼ˆéƒ¨åˆ†åŠŸèƒ½å¯èƒ½å—é™ï¼‰")
            return True  # å³ä½¿æ²¡æœ‰æ•°æ®é›†ï¼Œä¹Ÿå¯ä»¥è¿›è¡Œæ¨¡å‹åˆ†æ
    
    def analyze_loss_components(self, sample_batch_size=32):
        """åˆ†ææŸå¤±å‡½æ•°ç»„ä»¶"""
        print("ğŸ“Š åˆ†ææŸå¤±å‡½æ•°ç»„ä»¶...")
        
        try:
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            test_input = tf.random.normal((sample_batch_size, 100, 6), dtype=tf.float32)
            test_init_state = tf.zeros((sample_batch_size, self.state_dim), dtype=tf.float32)
            test_target = tf.random.normal((sample_batch_size, 100, 1), dtype=tf.float32)
            
            # è·å–æ¨¡å‹é¢„æµ‹å’Œé—¨æ§å‚æ•° - ä¿®å¤è§£åŒ…é—®é¢˜
            model_output = self.model([test_input, test_init_state], training=False)
            
            # å¤„ç†ä¸åŒçš„æ¨¡å‹è¾“å‡ºæ ¼å¼
            if isinstance(model_output, (list, tuple)):
                if len(model_output) == 2:
                    predictions, gate_params = model_output
                elif len(model_output) > 2:
                    # å¦‚æœè¾“å‡ºæ›´å¤šï¼Œå–å‰ä¸¤ä¸ª
                    predictions = model_output[0]
                    gate_params = model_output[1] if len(model_output) > 1 else None
                else:
                    predictions = model_output[0]
                    gate_params = None
            else:
                # å¦‚æœè¾“å‡ºæ˜¯å•ä¸ªå¼ é‡
                predictions = model_output
                gate_params = None
            
            # è®¡ç®—MSEæŸå¤±
            mse_loss = tf.reduce_mean(tf.square(test_target - predictions))
            print(f"ğŸ“ˆ MSEæŸå¤±: {mse_loss:.6f}")
            
            # åˆ›å»ºæŸå¤±å‡½æ•°å®ä¾‹
            from core.EMSC_losses import EMSCLoss
            loss_fn = EMSCLoss(state_dim=self.state_dim)
            
            # æ­£ç¡®è°ƒç”¨æŸå¤±å‡½æ•° - ç›´æ¥è°ƒç”¨callæ–¹æ³•
            total_loss = loss_fn.call(test_target, predictions, gate_params)
            print(f"ğŸ“Š æ€»æŸå¤±: {total_loss:.6f}")
            
            # åˆ†æé—¨æ§å‚æ•°ç»Ÿè®¡
            if gate_params and isinstance(gate_params, dict):
                gate_stats = {}
                for gate_name, gate_values in gate_params.items():
                    if isinstance(gate_values, tf.Tensor):
                        stats = {
                            'mean': float(tf.reduce_mean(gate_values).numpy()),
                            'std': float(tf.math.reduce_std(gate_values).numpy()),
                            'min': float(tf.reduce_min(gate_values).numpy()),
                            'max': float(tf.reduce_max(gate_values).numpy())
                        }
                        gate_stats[gate_name] = stats
                        print(f"ğŸ”§ é—¨æ§å‚æ•° {gate_name}: å‡å€¼={stats['mean']:.4f}, æ ‡å‡†å·®={stats['std']:.4f}, èŒƒå›´=[{stats['min']:.4f}, {stats['max']:.4f}]")
                
                # åˆ†æé—¨æ§å‚æ•°é—®é¢˜
                problems = []
                for gate_name, stats in gate_stats.items():
                    if abs(stats['mean']) > 2.0:
                        problems.append(f"{gate_name}å‚æ•°å‡å€¼è¿‡å¤§({stats['mean']:.3f})ï¼Œå¯èƒ½å¯¼è‡´æ¢¯åº¦ä¸ç¨³å®š")
                    if stats['std'] > 3.0:
                        problems.append(f"{gate_name}å‚æ•°æ–¹å·®è¿‡å¤§({stats['std']:.3f})ï¼Œå‚æ•°åˆ†å¸ƒä¸ç¨³å®š")
                    if stats['max'] - stats['min'] > 10.0:
                        problems.append(f"{gate_name}å‚æ•°èŒƒå›´è¿‡å®½({stats['max']:.3f} - {stats['min']:.3f})ï¼Œå¯èƒ½å­˜åœ¨æ¢¯åº¦çˆ†ç‚¸")
                
                return {
                    'mse_loss': float(mse_loss.numpy()),
                    'total_loss': float(total_loss.numpy()),
                    'gate_stats': gate_stats,
                    'problems': problems
                }
            else:
                return {
                    'mse_loss': float(mse_loss.numpy()),
                    'total_loss': float(total_loss.numpy()),
                    'gate_stats': {},
                    'problems': ['æ— æ³•è·å–é—¨æ§å‚æ•°ï¼Œä½¿ç”¨åŸºç¡€MSEæŸå¤±è¿›è¡Œåˆ†æ']
                }
                
        except Exception as e:
            print(f"âš ï¸  æŸå¤±åˆ†æå¤±è´¥: {e}")
            return {
                'mse_loss': None,
                'total_loss': None,
                'gate_stats': {},
                'problems': [f'æŸå¤±åˆ†æå¤±è´¥: {str(e)}']
            }
    
    def analyze_gradient_flow(self, sample_batch_size=16):
        """åˆ†ææ¢¯åº¦æµåŠ¨æƒ…å†µ"""
        print("\nğŸŒŠ åˆ†ææ¢¯åº¦æµåŠ¨...")
        
        if self.model is None:
            print("âŒ æ¨¡å‹æœªåŠ è½½")
            return
            
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_input = tf.random.normal((sample_batch_size, 50, 6))
        test_init_state = tf.zeros((sample_batch_size, self.state_dim))
        test_target = tf.random.normal((sample_batch_size, 50, 1))
        
        # è®¡ç®—æ¢¯åº¦
        with tf.GradientTape() as tape:
            predictions = self.model([test_input, test_init_state], training=True)
            loss = tf.reduce_mean(tf.square(test_target - predictions))
        
        gradients = tape.gradient(loss, self.model.trainable_variables)
        
        # åˆ†ææ¢¯åº¦ç»Ÿè®¡
        gradient_norms = []
        gradient_stats = []
        
        for i, grad in enumerate(gradients):
            if grad is not None:
                grad_norm = tf.norm(grad)
                grad_mean = tf.reduce_mean(tf.abs(grad))
                grad_max = tf.reduce_max(tf.abs(grad))
                
                gradient_norms.append(float(grad_norm))
                gradient_stats.append({
                    'layer': i,
                    'norm': float(grad_norm),
                    'mean': float(grad_mean),
                    'max': float(grad_max)
                })
                
                print(f"å±‚ {i:2d}: æ¢¯åº¦èŒƒæ•°={grad_norm:.2e}, å¹³å‡={grad_mean:.2e}, æœ€å¤§={grad_max:.2e}")
        
        # æ£€æµ‹æ¢¯åº¦é—®é¢˜
        max_norm = max(gradient_norms)
        min_norm = min(gradient_norms)
        
        if max_norm > 10:
            print("âš ï¸  æ£€æµ‹åˆ°æ¢¯åº¦çˆ†ç‚¸ï¼Œå»ºè®®è°ƒæ•´æ¢¯åº¦è£å‰ª")
        elif max_norm < 1e-7:
            print("âš ï¸  æ£€æµ‹åˆ°æ¢¯åº¦æ¶ˆå¤±ï¼Œå¯èƒ½å¯¼è‡´è®­ç»ƒåœæ»")
        elif min_norm / max_norm < 1e-3:
            print("âš ï¸  æ¢¯åº¦å·®å¼‚å¾ˆå¤§ï¼ŒæŸäº›å±‚å¯èƒ½è®­ç»ƒä¸å……åˆ†")
        else:
            print("âœ… æ¢¯åº¦æµåŠ¨æ­£å¸¸")
            
        return gradient_stats
    
    def analyze_model_capacity(self):
        """åˆ†ææ¨¡å‹å®¹é‡å’Œå¤æ‚åº¦"""
        print("ğŸ” åˆ†ææ¨¡å‹å®¹é‡...")
        
        try:
            # è·å–æ¨¡å‹å‚æ•°ç»Ÿè®¡
            total_params = self.model.count_params()
            trainable_params = sum([tf.size(var).numpy() for var in self.model.trainable_variables])
            
            # åˆ†æå„å±‚å‚æ•°åˆ†å¸ƒ
            layer_info = []
            for i, layer in enumerate(self.model.layers):
                if hasattr(layer, 'count_params') and layer.count_params() > 0:
                    layer_params = layer.count_params()
                    layer_info.append({
                        'name': layer.name,
                        'type': type(layer).__name__,
                        'params': layer_params,
                        'percentage': (layer_params / total_params) * 100
                    })
            
            print(f"ğŸ“Š æ¨¡å‹å‚æ•°ç»Ÿè®¡:")
            print(f"   æ€»å‚æ•°: {total_params:,}")
            print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
            
            # å®¹é‡åˆ†æ
            capacity_analysis = {
                'total_params': total_params,
                'trainable_params': trainable_params,
                'layer_info': layer_info
            }
            
            # åˆ¤æ–­æ¨¡å‹å®¹é‡æ˜¯å¦åˆé€‚
            problems = []
            if total_params < 1000:
                problems.append("æ¨¡å‹å‚æ•°è¿‡å°‘ï¼Œå¯èƒ½å®¹é‡ä¸è¶³ä»¥å­¦ä¹ å¤æ‚æ¨¡å¼")
            elif total_params > 100000:
                problems.append("æ¨¡å‹å‚æ•°è¿‡å¤šï¼Œå¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆé£é™©")
            
            # æ£€æŸ¥ç½‘ç»œæ·±åº¦å’Œå®½åº¦
            if self.hidden_dim < 16:
                problems.append(f"éšè—å±‚ç»´åº¦è¿‡å°({self.hidden_dim})ï¼Œå»ºè®®å¢åŠ åˆ°64æˆ–æ›´å¤§")
            if self.state_dim < 16:
                problems.append(f"çŠ¶æ€ç»´åº¦è¿‡å°({self.state_dim})ï¼Œå»ºè®®å¢åŠ åˆ°16æˆ–æ›´å¤§")
            
            capacity_analysis['problems'] = problems
            
            return capacity_analysis
            
        except Exception as e:
            print(f"âš ï¸  å®¹é‡åˆ†æå¤±è´¥: {e}")
            return {'problems': [f'å®¹é‡åˆ†æå¤±è´¥: {str(e)}']}
    
    def provide_comprehensive_solutions(self, loss_analysis, capacity_analysis):
        """æä¾›ç»¼åˆè§£å†³æ–¹æ¡ˆ"""
        print("\n" + "="*60)
        print("ğŸ¯ EMSCè®­ç»ƒè¯Šæ–­ç»“è®ºå’Œè§£å†³æ–¹æ¡ˆ")
        print("="*60)
        
        # åŸºäºMSEæŸå¤±å€¼è¯Šæ–­
        mse_loss = loss_analysis.get('mse_loss')
        if mse_loss is not None:
            print(f"\nğŸ“Š å½“å‰MSEæŸå¤±: {mse_loss:.6f}")
            
            if mse_loss > 1.0:
                print("ğŸ”´ è¯Šæ–­ç»“æœ: æŸå¤±å€¼è¿‡é«˜ï¼Œæ¨¡å‹é¢„æµ‹æ•ˆæœå¾ˆå·®")
                print("ğŸ’¡ ä¸»è¦é—®é¢˜:")
                print("   1. æ•°æ®æ ‡å‡†åŒ–å¯èƒ½æœ‰é—®é¢˜")
                print("   2. å­¦ä¹ ç‡å¯èƒ½è®¾ç½®ä¸å½“")
                print("   3. æ¨¡å‹ç»“æ„å¯èƒ½ä¸é€‚åˆæ•°æ®")
            elif mse_loss > 0.1:
                print("ğŸŸ¡ è¯Šæ–­ç»“æœ: æŸå¤±å€¼è¾ƒé«˜ï¼Œæœ‰æ”¹è¿›ç©ºé—´")
                print("ğŸ’¡ ä¸»è¦é—®é¢˜:")
                print("   1. å¯èƒ½éœ€è¦æ›´å¤šè®­ç»ƒæ—¶é—´")
                print("   2. å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥éœ€è¦ä¼˜åŒ–")
                print("   3. æ­£åˆ™åŒ–æƒé‡å¯èƒ½ä¸åˆé€‚")
            elif mse_loss > 0.01:
                print("ğŸŸ¢ è¯Šæ–­ç»“æœ: æŸå¤±å€¼åˆç†ï¼Œä½†å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–")
                print("ğŸ’¡ ä¼˜åŒ–æ–¹å‘:")
                print("   1. ä½¿ç”¨è‡ªé€‚åº”è®­ç»ƒç­–ç•¥")
                print("   2. è°ƒæ•´ç½‘ç»œç»“æ„")
                print("   3. ä¼˜åŒ–æ•°æ®é¢„å¤„ç†")
            else:
                print("ğŸŸ¢ è¯Šæ–­ç»“æœ: æŸå¤±å€¼å·²ç»å¾ˆä½ï¼Œæ¨¡å‹æ€§èƒ½è‰¯å¥½")
        
        # EMSCç‰¹å®šé—®é¢˜åˆ†æ
        print(f"\nğŸ”§ EMSCæ¨¡å‹ç‰¹å®šåˆ†æ:")
        
        solutions = []
        
        # é—¨æ§å‚æ•°é—®é¢˜
        problems = loss_analysis.get('problems', [])
        if problems:
            print("âŒ å‘ç°çš„é—®é¢˜:")
            for problem in problems:
                print(f"   - {problem}")
        
        # å®¹é‡é—®é¢˜
        capacity_problems = capacity_analysis.get('problems', [])
        if capacity_problems:
            print("ğŸ“¦ æ¨¡å‹å®¹é‡é—®é¢˜:")
            for problem in capacity_problems:
                print(f"   - {problem}")
        
        # ç»¼åˆè§£å†³æ–¹æ¡ˆ
        print(f"\nğŸš€ æ¨èè§£å†³æ–¹æ¡ˆ (æŒ‰ä¼˜å…ˆçº§æ’åº):")
        
        # è§£å†³æ–¹æ¡ˆ1: æ•°æ®å’Œé¢„å¤„ç†
        print("\n1ï¸âƒ£ æ•°æ®é¢„å¤„ç†ä¼˜åŒ– (æœ€é«˜ä¼˜å…ˆçº§)")
        print("   ğŸ“‹ é—®é¢˜: å¯èƒ½çš„æ•°æ®æ ‡å‡†åŒ–é—®é¢˜")
        print("   ğŸ”§ è§£å†³æ–¹æ¡ˆ:")
        print("   - æ£€æŸ¥è¾“å…¥æ•°æ®çš„æ•°å€¼èŒƒå›´ï¼Œç¡®ä¿åœ¨åˆç†åŒºé—´")
        print("   - ä½¿ç”¨ç¨³å¥çš„æ ‡å‡†åŒ–æ–¹æ³• (å¦‚RobustScaler)")
        print("   - ç¡®ä¿è®­ç»ƒé›†å’ŒéªŒè¯é›†ä½¿ç”¨ç›¸åŒçš„æ ‡å‡†åŒ–å‚æ•°")
        solutions.append("æ•°æ®é¢„å¤„ç†ä¼˜åŒ–")
        
        # è§£å†³æ–¹æ¡ˆ2: è‡ªé€‚åº”è®­ç»ƒ
        print("\n2ï¸âƒ£ ä½¿ç”¨è‡ªé€‚åº”è®­ç»ƒæ¨¡å¼ (å¼ºçƒˆæ¨è)")
        print("   ğŸ“‹ é—®é¢˜: ä¼ ç»Ÿè®­ç»ƒå®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜")
        print("   ğŸ”§ è§£å†³æ–¹æ¡ˆ:")
        print("   - ä½¿ç”¨å¾ªç¯å­¦ä¹ ç‡ + çƒ­é‡å¯")
        print("   - å¯ç”¨æƒé‡å™ªå£°æ³¨å…¥")
        print("   - åŠ¨æ€è°ƒæ•´æŸå¤±æƒé‡")
        print("   ğŸ’» å‘½ä»¤: python EMSC_Net/run_adaptive_training.py")
        solutions.append("è‡ªé€‚åº”è®­ç»ƒæ¨¡å¼")
        
        # è§£å†³æ–¹æ¡ˆ3: ç½‘ç»œç»“æ„è°ƒæ•´
        if self.hidden_dim <= 16 or self.state_dim <= 8:
            print("\n3ï¸âƒ£ å¢å¤§ç½‘ç»œå®¹é‡ (æ¨è)")
            print("   ğŸ“‹ é—®é¢˜: å½“å‰ç½‘ç»œå®¹é‡å¯èƒ½ä¸è¶³")
            print("   ğŸ”§ è§£å†³æ–¹æ¡ˆ:")
            print(f"   - å°†hidden_dimä»{self.hidden_dim}å¢åŠ åˆ°64")
            print(f"   - å°†state_dimä»{self.state_dim}å¢åŠ åˆ°16")
            print("   - è€ƒè™‘å¢åŠ ç½‘ç»œå±‚æ•°")
            print("   ğŸ’» å‘½ä»¤: åœ¨è®­ç»ƒæ—¶ä½¿ç”¨ --hidden_dim 64 --state_dim 16")
            solutions.append("å¢å¤§ç½‘ç»œå®¹é‡")
        
        # è§£å†³æ–¹æ¡ˆ4: å­¦ä¹ ç‡ç­–ç•¥
        print("\n4ï¸âƒ£ ä¼˜åŒ–å­¦ä¹ ç‡ç­–ç•¥")
        print("   ğŸ“‹ é—®é¢˜: å­¦ä¹ ç‡å¯èƒ½è¿‡å°æˆ–è°ƒåº¦ç­–ç•¥ä¸å½“")
        print("   ğŸ”§ è§£å†³æ–¹æ¡ˆ:")
        print("   - ä½¿ç”¨æ›´å¤§çš„åˆå§‹å­¦ä¹ ç‡ (1e-2 æˆ– 5e-2)")
        print("   - å¯ç”¨å¾ªç¯å­¦ä¹ ç‡")
        print("   - ä½¿ç”¨æ›´æ¿€è¿›çš„å­¦ä¹ ç‡è¡°å‡")
        print("   ğŸ’» å‘½ä»¤: ä½¿ç”¨ --learning_rate 1e-2 --cyclical_lr")
        solutions.append("ä¼˜åŒ–å­¦ä¹ ç‡ç­–ç•¥")
        
        # è§£å†³æ–¹æ¡ˆ5: æŸå¤±å‡½æ•°è°ƒæ•´
        print("\n5ï¸âƒ£ æŸå¤±å‡½æ•°æƒé‡è°ƒæ•´")
        print("   ğŸ“‹ é—®é¢˜: MSEæŸå¤±å’Œæ­£åˆ™åŒ–æŸå¤±æƒé‡ä¸å¹³è¡¡")
        print("   ğŸ”§ è§£å†³æ–¹æ¡ˆ:")
        print("   - åŠ¨æ€è°ƒæ•´æ­£åˆ™åŒ–æƒé‡")
        print("   - ä½¿ç”¨æ›´ç¨³å®šçš„æ­£åˆ™åŒ–ç­–ç•¥")
        print("   - ç›‘æ§å„æŸå¤±ç»„ä»¶çš„ç›¸å¯¹å¤§å°")
        solutions.append("æŸå¤±å‡½æ•°æƒé‡è°ƒæ•´")
        
        # ç«‹å³å¯æ‰§è¡Œçš„å‘½ä»¤
        print(f"\nâš¡ ç«‹å³å¯ç”¨çš„è§£å†³å‘½ä»¤:")
        print(f"# æœ€ä½³æ–¹æ¡ˆ - è‡ªé€‚åº”è®­ç»ƒ")
        print(f"python EMSC_Net/run_adaptive_training.py")
        print(f"")
        print(f"# å¢å¤§ç½‘ç»œ + è‡ªé€‚åº”è®­ç»ƒ")
        print(f"python -m training.EMSC_train \\")
        print(f"    --dataset dataset_EMSC_big \\")
        print(f"    --adaptive_training \\")
        print(f"    --hidden_dim 64 \\")
        print(f"    --state_dim 16 \\")
        print(f"    --learning_rate 1e-2 \\")
        print(f"    --epochs 2000")
        
        return {
            'solutions': solutions,
            'priority_order': [
                'æ•°æ®é¢„å¤„ç†ä¼˜åŒ–',
                'è‡ªé€‚åº”è®­ç»ƒæ¨¡å¼', 
                'å¢å¤§ç½‘ç»œå®¹é‡',
                'ä¼˜åŒ–å­¦ä¹ ç‡ç­–ç•¥',
                'æŸå¤±å‡½æ•°æƒé‡è°ƒæ•´'
            ]
        }
    
    def run_full_diagnosis(self):
        """è¿è¡Œå®Œæ•´çš„è®­ç»ƒè¯Šæ–­"""
        print("ğŸ”§ EMSCè®­ç»ƒè¯Šæ–­å·¥å…·")
        print("=" * 50)
        
        # åŠ è½½æ¨¡å‹å’Œæ•°æ®
        if not self.load_model_and_data():
            print("âŒ æ— æ³•ç»§ç»­è¯Šæ–­ï¼Œè¯·æ£€æŸ¥æ¨¡å‹å’Œæ•°æ®è·¯å¾„")
            return None
        
        # æ‰§è¡Œå„é¡¹åˆ†æ
        print("\nğŸ” å¼€å§‹æ‰§è¡Œè¯Šæ–­åˆ†æ...")
        
        # 1. æŸå¤±ç»„ä»¶åˆ†æ
        loss_analysis = self.analyze_loss_components()
        
        # 2. æ¨¡å‹å®¹é‡åˆ†æ  
        capacity_analysis = self.analyze_model_capacity()
        
        # 3. æä¾›ç»¼åˆè§£å†³æ–¹æ¡ˆ
        solutions = self.provide_comprehensive_solutions(loss_analysis, capacity_analysis)
        
        # è¿”å›å®Œæ•´çš„è¯Šæ–­ç»“æœ
        return {
            'loss_analysis': loss_analysis,
            'capacity_analysis': capacity_analysis,
            'solutions': solutions
        }


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='EMSCè®­ç»ƒè¯Šæ–­å·¥å…·')
    parser.add_argument('--model_path', type=str, help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--dataset_path', type=str, help='æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--state_dim', type=int, default=8, help='çŠ¶æ€ç»´åº¦')
    parser.add_argument('--hidden_dim', type=int, default=32, help='éšè—å±‚ç»´åº¦')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¯Šæ–­å™¨
    diagnosis = EMSCTrainingDiagnosis(
        model_path=args.model_path,
        dataset_path=args.dataset_path,
        state_dim=args.state_dim,
        hidden_dim=args.hidden_dim
    )
    
    # è¿è¡Œè¯Šæ–­
    results = diagnosis.run_full_diagnosis()
    
    if results:
        print("\nâœ… è¯Šæ–­å®Œæˆï¼Œè¯·æ ¹æ®å»ºè®®è°ƒæ•´è®­ç»ƒç­–ç•¥")
    else:
        print("\nâŒ è¯Šæ–­å¤±è´¥")


if __name__ == "__main__":
    main() 