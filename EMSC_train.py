"""
EMSCæ¨¡å‹ä¸»è®­ç»ƒè„šæœ¬
ä½¿ç”¨æ¨¡å—åŒ–ç»“æ„ç»„ç»‡è®­ç»ƒæµç¨‹ï¼Œæ”¯æŒå¤šCPUè®­ç»ƒ
"""

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import mixed_precision

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from EMSC_model import build_msc_model
from EMSC_data import EMSCDataGenerator, create_tf_dataset, load_dataset_from_npz
from EMSC_callbacks import MSCProgressCallback, create_early_stopping_callback, create_learning_rate_scheduler
from EMSC_cpu_monitor import create_cpu_monitor_callback
from EMSC_dynamic_batch import DynamicBatchTrainer, create_dynamic_batch_callback
try:
    from EMSC_cloud_io_optimizer import CloudIOOptimizer, create_cloud_optimized_training_config
    CLOUD_OPTIMIZER_AVAILABLE = True
except ImportError:
    CLOUD_OPTIMIZER_AVAILABLE = False

try:
    from EMSC_oss_downloader import download_dataset
    OSS_DOWNLOADER_AVAILABLE = True
except ImportError:
    OSS_DOWNLOADER_AVAILABLE = False
from EMSC_config import (create_training_config, save_training_config, 
                        parse_training_args, get_dataset_paths)
from EMSC_utils import (load_or_create_model_with_history, 
                       resume_training_from_checkpoint,
                       plot_final_training_summary,
                       print_training_summary)
from EMSC_losses import EMSCLoss

def check_environment(device_preference='auto'):
    """
    æ£€æŸ¥å¹¶é…ç½®è®­ç»ƒç¯å¢ƒ
    
    Args:
        device_preference: è®¾å¤‡åå¥½ ('auto', 'gpu', 'cpu')
                          - 'auto': è‡ªåŠ¨é€‰æ‹©ï¼ŒGPUä¼˜å…ˆï¼Œå›é€€åˆ°CPU
                          - 'gpu': å¼ºåˆ¶ä½¿ç”¨GPUï¼Œå¦‚æœä¸å¯ç”¨åˆ™æŠ¥é”™
                          - 'cpu': å¼ºåˆ¶ä½¿ç”¨CPU
    """
    print("æ£€æŸ¥è®­ç»ƒç¯å¢ƒ...")
    print(f"TensorFlowç‰ˆæœ¬: {tf.__version__}")
    print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"è®¾å¤‡åå¥½: {device_preference}")
    
    # æ£€æŸ¥GPUå¯ç”¨æ€§
    gpus = tf.config.list_physical_devices('GPU')
    print(f"æ£€æµ‹åˆ°çš„GPUè®¾å¤‡: {len(gpus)}")
    
    # æ ¹æ®ç”¨æˆ·åå¥½å†³å®šä½¿ç”¨çš„è®¾å¤‡
    if device_preference == 'cpu':
        print("ğŸ–¥ï¸  ç”¨æˆ·æŒ‡å®šä½¿ç”¨CPUï¼Œè·³è¿‡GPUé…ç½®")
        # å¼ºåˆ¶ç¦ç”¨GPUï¼Œå³ä½¿æœ‰GPUä¹Ÿä¸ä½¿ç”¨
        if gpus:
            tf.config.set_visible_devices([], 'GPU')
            print("âœ… å·²ç¦ç”¨æ‰€æœ‰GPUè®¾å¤‡ï¼Œå¼ºåˆ¶ä½¿ç”¨CPU")
        return setup_cpu_environment()
    
    elif device_preference == 'gpu':
        print("ğŸ® ç”¨æˆ·æŒ‡å®šå¼ºåˆ¶ä½¿ç”¨GPU")
        if not gpus:
            raise RuntimeError("âŒ ç”¨æˆ·æŒ‡å®šä½¿ç”¨GPUï¼Œä½†æœªæ£€æµ‹åˆ°ä»»ä½•GPUè®¾å¤‡ï¼")
        return setup_gpu_environment(gpus)
    
    else:  # device_preference == 'auto'
        print("ğŸ”„ è‡ªåŠ¨è®¾å¤‡é€‰æ‹©æ¨¡å¼ (GPUä¼˜å…ˆ)")
        if gpus:
            return setup_gpu_environment(gpus)
        else:
            print("æœªå‘ç°GPUè®¾å¤‡ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°CPUè®­ç»ƒ")
            return setup_cpu_environment()

def detect_environment():
    """
    æ£€æµ‹è¿è¡Œç¯å¢ƒï¼šæœ¬åœ° vs äº‘ç¯å¢ƒ
    
    Returns:
        str: 'local' æˆ– 'cloud'
    """
    # æ£€æµ‹äº‘ç¯å¢ƒçš„ç‰¹å¾
    cloud_indicators = [
        '/mnt/data',  # é˜¿é‡Œäº‘æŒ‚è½½è·¯å¾„
        '/opt/ml',    # AWS SageMaker
        '/kaggle',    # Kaggle
    ]
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    env_cloud_indicators = [
        'KUBERNETES_SERVICE_HOST',  # K8sç¯å¢ƒ
        'CLOUD_SHELL',             # äº‘shell
        'COLAB_GPU',               # Google Colab
    ]
    
    # æ£€æŸ¥è·¯å¾„æŒ‡æ ‡
    for indicator in cloud_indicators:
        if os.path.exists(indicator):
            return 'cloud'
    
    # æ£€æŸ¥OSSé…ç½®æ–‡ä»¶
    if os.path.exists('/mnt/data/msc_models/dataset_EMSC_big/oss_config.json'):
        return 'cloud'
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    for env_var in env_cloud_indicators:
        if os.environ.get(env_var):
            return 'cloud'
    
    # æ£€æŸ¥CPUæ ¸å¿ƒæ•°ï¼ˆäº‘ç¯å¢ƒé€šå¸¸æœ‰æ›´å¤šæ ¸å¿ƒï¼‰
    cpu_count = os.cpu_count() or 4
    if cpu_count >= 32:  # é«˜æ ¸å¿ƒæ•°å¯èƒ½æ˜¯äº‘ç¯å¢ƒ
        print(f"ğŸ” æ£€æµ‹åˆ°é«˜æ ¸å¿ƒæ•°CPU ({cpu_count})ï¼Œå¯èƒ½æ˜¯äº‘ç¯å¢ƒ")
    
    return 'local'

def setup_gpu_environment(gpus):
    """è®¾ç½®GPUè®­ç»ƒç¯å¢ƒ - åŒºåˆ†æœ¬åœ°å’Œäº‘ç¯å¢ƒ"""
    env_type = detect_environment()
    print(f"ğŸ® é…ç½®GPUè®­ç»ƒç¯å¢ƒ ({env_type})")
    print(f"å‘ç° {len(gpus)} ä¸ªGPUè®¾å¤‡:")
    
    for gpu in gpus:
        print(f"- {gpu}")
        # é…ç½®GPUå†…å­˜å¢é•¿
        try:
            tf.config.experimental.set_memory_growth(gpu, True)
            print(f"å·²ä¸º {gpu} å¯ç”¨å†…å­˜å¢é•¿")
        except RuntimeError as e:
            print(f"é…ç½®GPUå†…å­˜å¢é•¿æ—¶å‡ºé”™: {e}")
    
    # è®¾ç½®GPUä¸ºé»˜è®¤è®¾å¤‡
    try:
        tf.config.set_visible_devices(gpus[0], 'GPU')
        
        if env_type == 'local':
            # æœ¬åœ°GPUä¼˜åŒ–é…ç½®
            print("ğŸ  æœ¬åœ°GPUç¯å¢ƒä¼˜åŒ–:")
            
            # æœ¬åœ°ç¯å¢ƒå¯ç”¨TF32ä»¥æå‡æ€§èƒ½
            tf.config.experimental.enable_tensor_float_32_execution(True)
            print("âœ… å¯ç”¨TensorFloat-32ï¼ˆæœ¬åœ°GPUæ€§èƒ½ä¼˜åŒ–ï¼‰")
            
            # æœ¬åœ°ç¯å¢ƒçš„çº¿ç¨‹é…ç½®
            tf.config.threading.set_inter_op_parallelism_threads(0)  # ä½¿ç”¨é»˜è®¤
            tf.config.threading.set_intra_op_parallelism_threads(0)  # ä½¿ç”¨é»˜è®¤
            print("âœ… ä½¿ç”¨é»˜è®¤çº¿ç¨‹é…ç½®ï¼ˆæœ¬åœ°GPUä¼˜åŒ–ï¼‰")
            
        else:
            # äº‘GPUä¼˜åŒ–é…ç½®
            print("â˜ï¸  äº‘GPUç¯å¢ƒä¼˜åŒ–:")
            
            # äº‘ç¯å¢ƒç¦ç”¨TF32ä»¥æé«˜ç²¾åº¦ç¨³å®šæ€§
            tf.config.experimental.enable_tensor_float_32_execution(False)
            print("âœ… ç¦ç”¨TensorFloat-32ï¼ˆäº‘ç¯å¢ƒç²¾åº¦ä¼˜å…ˆï¼‰")
            
            # äº‘ç¯å¢ƒçš„çº¿ç¨‹é…ç½®ï¼ˆæ›´ä¿å®ˆï¼‰
            tf.config.threading.set_inter_op_parallelism_threads(4)
            tf.config.threading.set_intra_op_parallelism_threads(8)
            print("âœ… é…ç½®ä¿å®ˆçº¿ç¨‹è®¾ç½®ï¼ˆäº‘ç¯å¢ƒç¨³å®šæ€§ä¼˜å…ˆï¼‰")
        
        # é€šç”¨GPUé…ç½®
        tf.config.optimizer.set_jit(False)
        print("â„¹ï¸  ç¦ç”¨XLA JITç¼–è¯‘ï¼ˆEMSC while_loopå…¼å®¹æ€§ï¼‰")
        
        print(f"âœ… GPUç¯å¢ƒé…ç½®å®Œæˆ: {gpus[0]}")
        return None  # ä½¿ç”¨GPUæ—¶ä¸éœ€è¦è¿”å›workeræ•°
    except RuntimeError as e:
        raise RuntimeError(f"âŒ GPUè®¾å¤‡é…ç½®å¤±è´¥: {e}")

def setup_cpu_environment():
    """è®¾ç½®CPUè®­ç»ƒç¯å¢ƒ"""
    print("ğŸ–¥ï¸  é…ç½®CPUè®­ç»ƒç¯å¢ƒ")
    
    # è·å–CPUæ ¸å¿ƒæ•°
    cpu_count = os.cpu_count()
    if cpu_count is None:
        cpu_count = 4  # é»˜è®¤å€¼
    
    # é’ˆå¯¹é˜¿é‡Œäº‘ç­‰äº‘ç¯å¢ƒçš„CPUä¼˜åŒ–é…ç½®
    # ä½¿ç”¨æ‰€æœ‰å¯ç”¨CPUæ ¸å¿ƒï¼Œä¸ä¿ç•™
    num_workers = cpu_count
    
    # è®¾ç½®TensorFlowçº¿ç¨‹é…ç½® - æ›´æ¿€è¿›çš„è®¾ç½®
    tf.config.threading.set_inter_op_parallelism_threads(num_workers)
    tf.config.threading.set_intra_op_parallelism_threads(num_workers)
    
    # è®¾ç½®OpenMPçº¿ç¨‹æ•°ï¼ˆç”¨äºNumPyã€MKLç­‰åº“ï¼‰
    os.environ['OMP_NUM_THREADS'] = str(num_workers)
    os.environ['MKL_NUM_THREADS'] = str(num_workers)
    os.environ['OPENBLAS_NUM_THREADS'] = str(num_workers)
    os.environ['NUMEXPR_NUM_THREADS'] = str(num_workers)
    
    # ä¼˜åŒ–TensorFlowçš„CPUæ€§èƒ½
    os.environ['TF_NUM_INTEROP_THREADS'] = str(num_workers)
    os.environ['TF_NUM_INTRAOP_THREADS'] = str(num_workers)
    
    # å¯ç”¨æ‰€æœ‰CPUä¼˜åŒ–
    os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'  # å¯ç”¨OneDNNä¼˜åŒ–
    
    print(f"é˜¿é‡Œäº‘CPUç¯å¢ƒä¼˜åŒ–é…ç½®å®Œæˆ:")
    print(f"- æ€»CPUæ ¸å¿ƒæ•°: {cpu_count}")
    print(f"- è®­ç»ƒä½¿ç”¨çº¿ç¨‹æ•°: {num_workers}")
    print(f"- inter_op_parallelism_threads: {num_workers}")
    print(f"- intra_op_parallelism_threads: {num_workers}")
    print(f"- OMP_NUM_THREADS: {num_workers}")
    print(f"- å·²å¯ç”¨OneDNNä¼˜åŒ–")
    
    # æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ
    try:
        import psutil
        memory = psutil.virtual_memory()
        print(f"\nç³»ç»Ÿå†…å­˜ä¿¡æ¯:")
        print(f"æ€»å†…å­˜: {memory.total / (1024**3):.1f} GB")
        print(f"å¯ç”¨å†…å­˜: {memory.available / (1024**3):.1f} GB")
        print(f"å†…å­˜ä½¿ç”¨ç‡: {memory.percent}%")
        
        # æ˜¾ç¤ºCPUä¿¡æ¯
        print(f"\nCPUä¿¡æ¯:")
        print(f"ç‰©ç†CPUæ ¸å¿ƒæ•°: {psutil.cpu_count(logical=False)}")
        print(f"é€»è¾‘CPUæ ¸å¿ƒæ•°: {psutil.cpu_count(logical=True)}")
    except ImportError:
        print("æœªå®‰è£…psutilï¼Œè·³è¿‡ç³»ç»Ÿä¿¡æ¯æ£€æŸ¥")
    
    return num_workers

def get_optimal_batch_size(num_samples, num_workers):
    """
    è®¡ç®—æœ€ä¼˜æ‰¹å¤„ç†å¤§å° - åŒºåˆ†æœ¬åœ°å’Œäº‘ç¯å¢ƒ
    
    Args:
        num_samples: è®­ç»ƒæ ·æœ¬æ•°é‡
        num_workers: å·¥ä½œçº¿ç¨‹æ•°ï¼ˆCPUæ¨¡å¼ï¼‰æˆ–Noneï¼ˆGPUæ¨¡å¼ï¼‰
    
    Returns:
        int: æœ€ä¼˜æ‰¹å¤„ç†å¤§å°
    """
    if num_workers is None:  # GPUæ¨¡å¼
        env_type = detect_environment()
        
        if env_type == 'local':
            # æœ¬åœ°GPUç¯å¢ƒ - ä½¿ç”¨ä¸­ç­‰æ‰¹å¤„ç†å¤§å°
            base_batch = min(64, max(16, num_samples // 100))  # æ›´ä¿å®ˆçš„åŸºç¡€å¤§å°
            batch_size = base_batch
            print(f"æœ¬åœ°GPUæ‰¹æ¬¡å¤§å°: {batch_size}")
        else:
            # äº‘GPUç¯å¢ƒ - ä½¿ç”¨è¾ƒå¤§çš„æ‰¹å¤„ç†å¤§å°
            batch_size = min(128, num_samples // 50)
            print(f"äº‘GPUæ‰¹æ¬¡å¤§å°: {batch_size}")
        
        return (batch_size // 8) * 8  # ç¡®ä¿æ˜¯8çš„å€æ•°
    
    # CPUæ¨¡å¼ä¸‹çš„æ‰¹å¤„ç†å¤§å°è®¡ç®— - æ›´ç§¯æçš„é…ç½®
    # åŸºç¡€æ‰¹æ¬¡å¤§å° - ä¸ºCPUè®­ç»ƒå¢åŠ æ›´å¤§çš„åŸºæ•°
    base_batch = min(64, max(32, num_samples // 50))  # å¢åŠ åŸºç¡€æ‰¹æ¬¡å¤§å°
    
    # æ ¹æ®CPUçº¿ç¨‹æ•°è°ƒæ•´ - è®©æ¯ä¸ªçº¿ç¨‹å¤„ç†æ›´å¤šæ•°æ®
    # ä½¿ç”¨æ›´æ¿€è¿›çš„å€æ•°ï¼Œå……åˆ†åˆ©ç”¨å¤šæ ¸CPU
    if num_workers >= 16:  # é«˜æ ¸å¿ƒæ•°CPUï¼ˆé˜¿é‡Œäº‘é«˜é…ï¼‰
        multiplier = 2
    elif num_workers >= 8:  # ä¸­ç­‰æ ¸å¿ƒæ•°CPU
        multiplier = 3
    else:  # ä½æ ¸å¿ƒæ•°CPU
        multiplier = 4
    
    optimal_batch = base_batch * multiplier
    
    # ç¡®ä¿æ‰¹æ¬¡å¤§å°åˆç†
    optimal_batch = min(optimal_batch, num_samples)  # ä¸è¶…è¿‡æ ·æœ¬æ€»æ•°
    optimal_batch = max(16, optimal_batch)  # æœ€å°16
    
    # ç¡®ä¿æ˜¯8çš„å€æ•°ï¼ˆå¯¹å†…å­˜å¯¹é½å’Œå‘é‡åŒ–æœ‰åˆ©ï¼‰
    optimal_batch = (optimal_batch // 8) * 8
    
    print(f"CPUæ‰¹æ¬¡å¤§å°è®¡ç®—: åŸºç¡€={base_batch}, çº¿ç¨‹æ•°={num_workers}, å€æ•°={multiplier}, æœ€ç»ˆ={optimal_batch}")
    
    return optimal_batch

def warmup_gpu_model(model, sample_batch_size=1, max_sequence_length=100):
    """
    GPUæ¨¡å‹é¢„çƒ­ï¼Œé¢„ç¼–è¯‘tf.while_loopå›¾
    è§£å†³ç¬¬ä¸€æ¬¡æ‰§è¡Œæ—¶çš„é•¿æ—¶é—´å¡é¡¿é—®é¢˜
    """
    print("ğŸ”¥ GPUæ¨¡å‹é¢„çƒ­ä¸­...")
    
    try:
        # åˆ›å»ºå°è§„æ¨¡çš„æ ·æœ¬æ•°æ®è¿›è¡Œé¢„çƒ­
        warmup_input = tf.random.normal((sample_batch_size, max_sequence_length, 6), dtype=tf.float32)
        warmup_init_state = tf.zeros((sample_batch_size, 8), dtype=tf.float32)
        
        # ç¬¬ä¸€æ¬¡å‰å‘ä¼ æ’­ - ç¼–è¯‘while_loopå›¾
        print("  ğŸ”„ æ‰§è¡Œç¬¬ä¸€æ¬¡å‰å‘ä¼ æ’­ï¼ˆå›¾ç¼–è¯‘ï¼‰...")
        start_time = tf.timestamp()
        
        _ = model([warmup_input, warmup_init_state], training=False)
        
        compile_time = tf.timestamp() - start_time
        print(f"  âœ… å›¾ç¼–è¯‘å®Œæˆï¼Œè€—æ—¶: {compile_time:.2f}ç§’")
        
        # ç¬¬äºŒæ¬¡å‰å‘ä¼ æ’­ - éªŒè¯ç¼–è¯‘æ•ˆæœ
        print("  ğŸ”„ æ‰§è¡Œç¬¬äºŒæ¬¡å‰å‘ä¼ æ’­ï¼ˆéªŒè¯åŠ é€Ÿï¼‰...")
        start_time = tf.timestamp()
        
        _ = model([warmup_input, warmup_init_state], training=False)
        
        exec_time = tf.timestamp() - start_time
        print(f"  âš¡ æ‰§è¡Œæ—¶é—´: {exec_time:.2f}ç§’")
        
        print("ğŸ‰ GPUæ¨¡å‹é¢„çƒ­å®Œæˆï¼è®­ç»ƒå°†ç«‹å³å¼€å§‹")
        return True
        
    except Exception as e:
        print(f"âš ï¸  GPUé¢„çƒ­å¤±è´¥: {e}")
        print("ç»§ç»­è®­ç»ƒï¼Œä½†ç¬¬ä¸€ä¸ªepochå¯èƒ½è¾ƒæ…¢...")
        return False

def main(args=None):
    # è§£æå‘½ä»¤è¡Œå‚æ•°ï¼ˆå¦‚æœæ²¡æœ‰ä¼ å…¥åˆ™è§£æï¼‰
    if args is None:
        args = parse_training_args()
    
    # æ£€æŸ¥å¹¶é…ç½®ç¯å¢ƒ
    num_workers = check_environment(device_preference=args.device)
    
    # å¼ºåˆ¶ç¦ç”¨æ··åˆç²¾åº¦ï¼Œç¡®ä¿CPUå’ŒGPUæ•°å€¼ä¸€è‡´æ€§
    tf.keras.mixed_precision.set_global_policy('float32')
    tf.keras.backend.set_floatx('float32')
    print("å¼ºåˆ¶ä½¿ç”¨float32ç²¾åº¦è®­ç»ƒï¼ˆç¦ç”¨æ··åˆç²¾åº¦ï¼‰")
    
    # äº‘ç¯å¢ƒI/Oä¼˜åŒ–
    cloud_optimizer = None
    if args.cloud_io_optimize:
        if CLOUD_OPTIMIZER_AVAILABLE:
            print("ğŸŒ¥ï¸  å¯ç”¨é˜¿é‡Œäº‘I/Oä¼˜åŒ–...")
            cloud_optimizer = CloudIOOptimizer(
                io_buffer_size=128,      # æ›´å¤§çš„I/Oç¼“å†²
                prefetch_factor=16,      # æ¿€è¿›é¢„å–
                io_threads=min(32, num_workers * 2) if num_workers else 16,
                memory_cache_size=1024   # 1GBå†…å­˜ç¼“å­˜
            )
            cloud_optimizer.optimize_cloud_environment()
        else:
            print("âš ï¸  äº‘ä¼˜åŒ–æ¨¡å—ä¸å¯ç”¨ï¼Œè·³è¿‡ä¼˜åŒ–")
    
    # è·å–æ•°æ®é›†è·¯å¾„
    paths = get_dataset_paths(args.dataset)
    base_dataset_dir = paths['dataset_dir']
    
    # æ ¹æ®ç½‘ç»œç»“æ„åˆ›å»ºå­æ–‡ä»¶å¤¹
    network_structure = f"6-{args.hidden_dim}-{args.hidden_dim}-{args.state_dim}-1"
    dataset_dir = os.path.join(base_dataset_dir, f"network_{network_structure}")
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(dataset_dir, exist_ok=True)
    print(f"ç½‘ç»œç»“æ„: {network_structure}")
    print(f"æ¨¡å‹ä¿å­˜ç›®å½•: {dataset_dir}")
    
    model_name = paths['model_name']
    best_model_name = paths['best_model_name']
    dataset_path = paths['dataset_path']
    
    # åˆ›å»ºå’Œä¿å­˜è®­ç»ƒé…ç½®
    training_config = create_training_config(
        state_dim=args.state_dim,
        input_dim=6,
        hidden_dim=args.hidden_dim,
        learning_rate=args.learning_rate,
        epochs=args.epochs,
        batch_size=args.batch_size,
        save_frequency=args.save_frequency
    )
    save_training_config(training_config, dataset_dir)
    
    # æ•°æ®é›†ä¼˜å…ˆçº§ç­–ç•¥
    print(f"ğŸ” æ•°æ®é›†ä¼˜å…ˆçº§æ£€æŸ¥...")
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºäº‘ç¯å¢ƒï¼ˆé€šè¿‡OSSé…ç½®æ–‡ä»¶å­˜åœ¨åˆ¤æ–­ï¼‰
    oss_config_path = '/mnt/data/msc_models/dataset_EMSC_big/oss_config.json'
    is_cloud_environment = os.path.exists(oss_config_path)
    
    if is_cloud_environment:
        print(f"ğŸŒ¥ï¸  æ£€æµ‹åˆ°äº‘ç¯å¢ƒï¼Œå¯ç”¨äº‘æ•°æ®é›†ä¼˜å…ˆçº§ç­–ç•¥")
        
        # äº‘ç¯å¢ƒä¼˜å…ˆçº§ï¼šå½“å‰ç›®å½• -> OSSä¸‹è½½ -> OSSå†…è·¯å¾„
        current_dir_dataset = os.path.join(os.getcwd(), os.path.basename(dataset_path))
        oss_internal_path = "/mnt/data/msc_models/dataset_EMSC_big/dataset_EMSC_big.npz"
        
        print(f"ä¼˜å…ˆçº§1: å½“å‰ç›®å½• - {current_dir_dataset}")
        print(f"ä¼˜å…ˆçº§2: OSSä¸‹è½½åˆ°å½“å‰ç›®å½•")
        print(f"ä¼˜å…ˆçº§3: OSSå†…è·¯å¾„ - {oss_internal_path}")
        
        # ä¼˜å…ˆçº§1: æ£€æŸ¥å½“å‰è¿è¡Œç›®å½•
        if os.path.exists(current_dir_dataset):
            file_size = os.path.getsize(current_dir_dataset)
            print(f"âœ… ä½¿ç”¨å½“å‰ç›®å½•æ•°æ®é›†: {current_dir_dataset}")
            print(f"   æ–‡ä»¶å¤§å°: {file_size / (1024*1024):.1f}MB")
            dataset_path = current_dir_dataset
        
        # ä¼˜å…ˆçº§2: ä»OSSä¸‹è½½åˆ°å½“å‰ç›®å½•
        elif OSS_DOWNLOADER_AVAILABLE:
            try:
                print(f"ğŸ“¥ å½“å‰ç›®å½•æ— æ•°æ®é›†ï¼Œå°è¯•ä»OSSä¸‹è½½...")
                print(f"OSSé…ç½®æ–‡ä»¶: {oss_config_path}")
                print(f"ä¸‹è½½åˆ°: {current_dir_dataset}")
                
                downloaded_path = download_dataset(oss_config_path, current_dir_dataset)
                print(f"âœ… æ•°æ®é›†ä¸‹è½½å®Œæˆ: {downloaded_path}")
                dataset_path = downloaded_path
                
            except Exception as e:
                print(f"âš ï¸  OSSä¸‹è½½å¤±è´¥: {e}")
                
                # ä¼˜å…ˆçº§3: ä½¿ç”¨OSSå†…è·¯å¾„
                if os.path.exists(oss_internal_path):
                    file_size = os.path.getsize(oss_internal_path)
                    print(f"âœ… ä½¿ç”¨OSSå†…è·¯å¾„æ•°æ®é›†: {oss_internal_path}")
                    print(f"   æ–‡ä»¶å¤§å°: {file_size / (1024*1024):.1f}MB")
                    dataset_path = oss_internal_path
                else:
                    print(f"âŒ OSSå†…è·¯å¾„ä¹Ÿä¸å­˜åœ¨: {oss_internal_path}")
                    raise ValueError(f"æ‰€æœ‰æ•°æ®é›†è·¯å¾„éƒ½ä¸å¯ç”¨")
        
        # å¦‚æœOSSä¸‹è½½å™¨ä¸å¯ç”¨ï¼Œç›´æ¥å°è¯•OSSå†…è·¯å¾„
        else:
            if os.path.exists(oss_internal_path):
                file_size = os.path.getsize(oss_internal_path)
                print(f"âœ… OSSä¸‹è½½å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨OSSå†…è·¯å¾„: {oss_internal_path}")
                print(f"   æ–‡ä»¶å¤§å°: {file_size / (1024*1024):.1f}MB")
                dataset_path = oss_internal_path
            else:
                print(f"âŒ OSSå†…è·¯å¾„ä¸å­˜åœ¨: {oss_internal_path}")
                raise ValueError(f"æ•°æ®é›†ä¸å¯ç”¨ï¼ŒOSSä¸‹è½½å™¨ä¸å¯ç”¨ä¸”OSSå†…è·¯å¾„ä¸å­˜åœ¨")
    
    else:
        # å•æœºç¯å¢ƒï¼šç›´æ¥ä½¿ç”¨ç»™å®šè·¯å¾„
        print(f"ğŸ’» æ£€æµ‹åˆ°å•æœºç¯å¢ƒï¼Œä½¿ç”¨ç»™å®šè·¯å¾„")
        print(f"æ•°æ®é›†è·¯å¾„: {dataset_path}")
        
        if os.path.exists(dataset_path):
            file_size = os.path.getsize(dataset_path)
            print(f"âœ… ä½¿ç”¨æŒ‡å®šæ•°æ®é›†: {dataset_path}")
            print(f"   æ–‡ä»¶å¤§å°: {file_size / (1024*1024):.1f}MB")
        else:
            print(f"âŒ æŒ‡å®šçš„æ•°æ®é›†ä¸å­˜åœ¨: {dataset_path}")
            raise ValueError(f"æ•°æ®é›†ä¸å­˜åœ¨: {dataset_path}")
    
    # åŠ è½½æ•°æ®é›†
    print(f"ğŸ“‚ åŠ è½½æ•°æ®é›†: {dataset_path}")
    X_paths, Y_paths = load_dataset_from_npz(dataset_path)
    if X_paths is None or Y_paths is None:
        print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥!")
        print(f"ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        print(f"   1. æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶æ˜¯å¦å®Œæ•´: {dataset_path}")
        if is_cloud_environment:
            print(f"   2. åˆ é™¤å½“å‰ç›®å½•çš„æ•°æ®é›†æ–‡ä»¶ï¼Œé‡æ–°ä»OSSä¸‹è½½")
            print(f"   3. æ£€æŸ¥OSSé…ç½®æ–‡ä»¶: {oss_config_path}")
            print(f"   4. æ£€æŸ¥OSSå†…è·¯å¾„: /mnt/data/msc_models/dataset_EMSC_big/dataset_EMSC_big.npz")
        else:
            print(f"   2. æ£€æŸ¥æ•°æ®é›†è·¯å¾„æ˜¯å¦æ­£ç¡®")
            print(f"   3. ç¡®è®¤æ•°æ®é›†æ–‡ä»¶æ ¼å¼æ­£ç¡®")
        raise ValueError("æ•°æ®é›†åŠ è½½å¤±è´¥")
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    print("å‡†å¤‡è®­ç»ƒåºåˆ—...")
    init_states = np.zeros((len(X_paths), training_config['STATE_DIM']), dtype=np.float32)
    
    # éšæœºæ‰“ä¹±åºåˆ—
    print("éšæœºæ‰“ä¹±è®­ç»ƒåºåˆ—...")
    np.random.seed(training_config['random_seed'])
    indices = np.random.permutation(len(X_paths))
    X_paths = [X_paths[i] for i in indices]
    Y_paths = [Y_paths[i] for i in indices]
    init_states = init_states[indices]
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train_size = int(training_config['train_test_split_ratio'] * len(X_paths))
    X_train = X_paths[:train_size]
    Y_train = Y_paths[:train_size]
    init_states_train = init_states[:train_size]
    
    X_val = X_paths[train_size:]
    Y_val = Y_paths[train_size:]
    init_states_val = init_states[train_size:]
    
    print(f"è®­ç»ƒé›†å¤§å°: {len(X_train)}")
    print(f"éªŒè¯é›†å¤§å°: {len(X_val)}")
    
    # ç¡®å®šæ‰¹å¤„ç†å¤§å°ï¼šä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„batch_sizeï¼Œå¦åˆ™è‡ªåŠ¨è®¡ç®—
    if args.batch_size is not None:
        batch_size = args.batch_size
        optimal_batch_size = get_optimal_batch_size(len(X_train), num_workers)
        print(f"ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„batch_size: {batch_size}")
        if batch_size != optimal_batch_size:
            print(f"æ³¨æ„ï¼šå»ºè®®çš„batch_sizeä¸º: {optimal_batch_size}")
    else:
        batch_size = get_optimal_batch_size(len(X_train), num_workers)
        print(f"æœªæŒ‡å®šbatch_sizeï¼Œä½¿ç”¨è‡ªåŠ¨è®¡ç®—å€¼: {batch_size}")
    
    # åˆ›å»ºTensorFlowæ•°æ®é›† - é’ˆå¯¹äº‘ç¯å¢ƒä¼˜åŒ–
    print("åˆ›å»ºTensorFlowæ•°æ®é›†...")
    
    if cloud_optimizer:
        # ä½¿ç”¨äº‘ä¼˜åŒ–çš„æ•°æ®é›†åˆ›å»º
        print("ğŸŒ¥ï¸  ä½¿ç”¨äº‘ç¯å¢ƒä¼˜åŒ–æ•°æ®é›†...")
        train_dataset = cloud_optimizer.create_optimized_dataset(
            X_train, Y_train, init_states_train, batch_size
        )
        val_dataset = cloud_optimizer.create_optimized_dataset(
            X_val, Y_val, init_states_val, batch_size
        )
        
        # äº‘ç¯å¢ƒæ€§èƒ½ç›‘æ§
        from EMSC_cloud_io_optimizer import monitor_cloud_performance
        monitor_cloud_performance()
        
    else:
        # æ ‡å‡†æ•°æ®é›†åˆ›å»º - åŒºåˆ†ç¯å¢ƒä¼˜åŒ–æ•°æ®åŠ è½½å¹¶è¡Œåº¦
        if num_workers is not None:  # CPUæ¨¡å¼
            data_parallel_calls = min(num_workers, 16)  # é™åˆ¶æœ€å¤§å¹¶è¡Œåº¦é¿å…è¿‡åº¦ç«äº‰
            prefetch_buffer = min(batch_size * 4, 64)  # é¢„å–ç¼“å†²åŒº
            print(f"CPUä¼˜åŒ–: æ•°æ®å¹¶è¡Œåº¦={data_parallel_calls}, é¢„å–ç¼“å†²={prefetch_buffer}")
        else:  # GPUæ¨¡å¼
            env_type = detect_environment()
            if env_type == 'local':
                # æœ¬åœ°GPUç¯å¢ƒ - ä½¿ç”¨è¾ƒå°çš„å¹¶è¡Œåº¦å’Œç¼“å†²åŒº
                data_parallel_calls = 4  # æœ¬åœ°ç¯å¢ƒä½¿ç”¨å›ºå®šå¹¶è¡Œåº¦
                prefetch_buffer = max(2, batch_size // 8)  # è¾ƒå°çš„é¢„å–ç¼“å†²
                print(f"æœ¬åœ°GPUä¼˜åŒ–: æ•°æ®å¹¶è¡Œåº¦={data_parallel_calls}, é¢„å–ç¼“å†²={prefetch_buffer}")
            else:
                # äº‘GPUç¯å¢ƒ - ä½¿ç”¨è‡ªåŠ¨è°ƒä¼˜
                data_parallel_calls = tf.data.AUTOTUNE
                prefetch_buffer = tf.data.AUTOTUNE
                print(f"äº‘GPUä¼˜åŒ–: ä½¿ç”¨AUTOTUNE")
        
        train_dataset = create_tf_dataset(
            X_train, Y_train, init_states_train,
            batch_size=batch_size,
            shuffle=True,
            num_parallel_calls=data_parallel_calls
        ).prefetch(prefetch_buffer)
        
        val_dataset = create_tf_dataset(
            X_val, Y_val, init_states_val,
            batch_size=batch_size,
            shuffle=False,
            num_parallel_calls=data_parallel_calls
        ).prefetch(prefetch_buffer)
    
    print(f"æ•°æ®åŠ è½½é…ç½®:")
    print(f"- æœ€ç»ˆä½¿ç”¨çš„æ‰¹å¤„ç†å¤§å°: {batch_size}")
    print(f"- æ•°æ®åŠ è½½çº¿ç¨‹æ•°: {num_workers if num_workers is not None else 'GPUæ¨¡å¼'}")
    
    # è®¡ç®—æœ€å¤§åºåˆ—é•¿åº¦
    max_seq_length = max(len(x) for x in X_paths)
    print(f"æ•°æ®é›†ä¸­æœ€å¤§åºåˆ—é•¿åº¦: {max_seq_length}")
    
    # åŠ è½½æˆ–åˆ›å»ºæ¨¡å‹
    epoch_offset = 0
    is_new_model = None
    if args.resume:
        print("å°è¯•æ¢å¤è®­ç»ƒ...")
        model, epoch_offset = resume_training_from_checkpoint(
            model_path=dataset_dir,
            model_name=model_name,
            best_model_name=best_model_name,
            resume_from_best=True,
            state_dim=args.state_dim,
            input_dim=6,
            output_dim=1,
            hidden_dim=args.hidden_dim,
            num_internal_layers=2,
            max_sequence_length=max_seq_length
        )
        
        if model is None:
            print("æ— æ³•æ¢å¤è®­ç»ƒï¼Œå°†åˆ›å»ºæ–°æ¨¡å‹")
            model, is_new_model = load_or_create_model_with_history(
                model_path=dataset_dir,
                model_name=model_name,
                best_model_name=best_model_name,
                state_dim=args.state_dim,
                input_dim=6,
                output_dim=1,
                hidden_dim=args.hidden_dim,
                num_internal_layers=2,
                max_sequence_length=max_seq_length
            )
    else:
        print("ä»å¤´å¼€å§‹è®­ç»ƒ...")
        model, is_new_model = load_or_create_model_with_history(
            model_path=dataset_dir,
            model_name=model_name,
            best_model_name=best_model_name,
            state_dim=args.state_dim,
            input_dim=6,
            output_dim=1,
            hidden_dim=args.hidden_dim,
            num_internal_layers=2,
            max_sequence_length=max_seq_length
        )
    
    # ç¼–è¯‘æ¨¡å‹ï¼Œæ·»åŠ æ¢¯åº¦è£å‰ªä»¥æé«˜æ•°å€¼ç¨³å®šæ€§
    optimizer = Adam(
        learning_rate=args.learning_rate,
        clipnorm=1.0,      # æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
        clipvalue=0.5      # æ¢¯åº¦å€¼è£å‰ª
    )
    custom_loss = EMSCLoss(state_dim=args.state_dim)
    model.compile(
        optimizer=optimizer,
        loss=custom_loss,
        # EMSCæ¨¡å‹ä½¿ç”¨tf.while_loopï¼Œä¸JITç¼–è¯‘ä¸å…¼å®¹
        # while_loopåˆ›å»ºåŠ¨æ€æ§åˆ¶æµï¼ŒJITç¼–è¯‘è¦æ±‚é™æ€å›¾ç»“æ„
        jit_compile=False
    )
    
    if is_new_model:
        model.summary()
    
    # GPUæ¨¡å‹é¢„çƒ­ï¼ˆä»…é™GPUæ¨¡å¼ï¼‰
    if num_workers is None:  # GPUæ¨¡å¼
        env_type = detect_environment()
        if env_type == 'local':
            # æœ¬åœ°GPUéœ€è¦é¢„çƒ­æ¥é¿å…å¡é¡¿
            print("ğŸ  æœ¬åœ°GPUç¯å¢ƒ - æ‰§è¡Œæ¨¡å‹é¢„çƒ­")
            warmup_gpu_model(model, sample_batch_size=1, max_sequence_length=min(200, max_seq_length))
        else:
            # äº‘GPUç¯å¢ƒå¯é€‰é¢„çƒ­
            print("â˜ï¸  äº‘GPUç¯å¢ƒ - è·³è¿‡é¢„çƒ­ï¼ˆå¯é€‰ä¼˜åŒ–ï¼‰")
    
    # åˆ›å»ºå›è°ƒ
    progress_callback = MSCProgressCallback(
        save_path=dataset_dir,
        model_name=model_name,
        best_model_name=best_model_name,
        save_frequency=args.save_frequency
    )
    
    early_stopping = create_early_stopping_callback()
    
    # åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨
    lr_scheduler = create_learning_rate_scheduler(
        initial_learning_rate=args.learning_rate,
        decay_type='validation',  # ä½¿ç”¨åŸºäºéªŒè¯æŸå¤±çš„åŠ¨æ€è°ƒæ•´
        decay_steps=args.epochs,  # æ€»epochsæ•°
        decay_rate=0.9,          # æŒ‡æ•°è¡°å‡ç‡ï¼ˆå½“ä½¿ç”¨exponentialæ—¶ï¼‰
        min_learning_rate=1e-6,  # æœ€å°å­¦ä¹ ç‡
        patience=min(int(args.epochs/50),50),              # éªŒè¯æŸå¤±ä¸æ”¹å–„çš„å®¹å¿è½®æ•°
        factor=0.5,             # å­¦ä¹ ç‡è¡°å‡å› å­
        verbose=1               # æ‰“å°å­¦ä¹ ç‡å˜åŒ–
    )
    
    # åˆ›å»ºCPUç›‘æ§å›è°ƒï¼ˆä»…CPUè®­ç»ƒæ¨¡å¼ä¸”ç”¨æˆ·å¯ç”¨æ—¶ï¼Œä¸”ä¸ä¸åŠ¨æ€æ‰¹æ¬¡å†²çªï¼‰
    cpu_monitor = None
    if num_workers is not None and args.monitor_cpu and not args.dynamic_batch:
        cpu_monitor = create_cpu_monitor_callback(monitor_interval=30, verbose=True)
        print("å·²å¯ç”¨CPUä½¿ç”¨ç‡ç›‘æ§")
    elif num_workers is not None and args.monitor_cpu and args.dynamic_batch:
        print("æ³¨æ„ï¼šåŠ¨æ€æ‰¹æ¬¡è°ƒæ•´å·²åŒ…å«CPUç›‘æ§åŠŸèƒ½ï¼Œ--monitor_cpuå°†è¢«å¿½ç•¥")
    
    # å‡†å¤‡å›è°ƒåˆ—è¡¨
    callbacks = [progress_callback, early_stopping, lr_scheduler]
    if cpu_monitor is not None:
        callbacks.append(cpu_monitor)
    
    # è®­ç»ƒæ¨¡å‹
    remaining_epochs = args.epochs
    if remaining_epochs <= 0:
        print(f"æ¨¡å‹å·²ç»è®­ç»ƒäº† {epoch_offset} epochsï¼Œè¾¾åˆ°è®¾å®šçš„æ€»epochs {args.epochs}")
        print("å¦‚éœ€ç»§ç»­è®­ç»ƒï¼Œè¯·å¢åŠ æ€»epochsæ•°")
    else:
        print(f"\nå¼€å§‹è®­ç»ƒ MSC æ¨¡å‹...")
        print(f"å·²å®Œæˆepochs: {epoch_offset}")
        print(f"å‰©ä½™epochs: {remaining_epochs}")
        print(f"æ€»epochsç›®æ ‡: {args.epochs + epoch_offset}")
        print(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
        print(f"ä¿å­˜é¢‘ç‡: æ¯ {args.save_frequency} epochs")
        print(f"æ—©åœè®¾ç½®: patience={15}, min_delta={1e-4}")
        print(f"å­¦ä¹ ç‡è°ƒåº¦: åˆå§‹={args.learning_rate}, æœ€å°={1e-6}, åŠ¨æ€è°ƒæ•´")
        print(f"æ¨¡å‹ä¿å­˜è·¯å¾„: {dataset_dir}")
        print(f"è®­ç»ƒæ•°æ®å¤§å°: {len(X_train)}")
        print(f"éªŒè¯æ•°æ®å¤§å°: {len(X_val)}")
        env_info = f"({'æœ¬åœ°' if detect_environment() == 'local' else 'äº‘'})" if num_workers is None else ""
        print(f"è®­ç»ƒæ¨¡å¼: {'GPU ' + env_info if num_workers is None else 'CPU (å¤šçº¿ç¨‹)'}")
        if num_workers is None:
            env_type = detect_environment()
            print(f"GPUä¼˜åŒ–è®¾ç½® ({env_type}):")
            print(f"  - XLA JITç¼–è¯‘: å·²ç¦ç”¨ (while_loopå…¼å®¹æ€§)")
            if env_type == 'local':
                print(f"  - TensorFloat-32: å·²å¯ç”¨ (æœ¬åœ°æ€§èƒ½ä¼˜åŒ–)")
                print(f"  - çº¿ç¨‹é…ç½®: ä½¿ç”¨é»˜è®¤ (æœ¬åœ°ä¼˜åŒ–)")
            else:
                print(f"  - TensorFloat-32: å·²ç¦ç”¨ (äº‘ç¯å¢ƒç²¾åº¦ä¼˜å…ˆ)")
                print(f"  - çº¿ç¨‹é…ç½®: ä¿å®ˆè®¾ç½® (äº‘ç¯å¢ƒç¨³å®šæ€§)")
            print(f"  - æ¢¯åº¦è£å‰ª: clipnorm=1.0, clipvalue=0.5")
            print(f"  - æ•°å€¼ç¨³å®šæ€§: EMSCLossä¿æŠ¤ + æ¢¯åº¦è£å‰ª")
        
        # ä½¿ç”¨æ€§èƒ½ä¼˜åŒ–çš„è®­ç»ƒé…ç½® - é’ˆå¯¹é˜¿é‡Œäº‘CPUä¼˜åŒ–
        if num_workers is not None and args.dynamic_batch:  # CPUæ¨¡å¼ + åŠ¨æ€æ‰¹æ¬¡
            print(f"ğŸš€ å¯ç”¨åŠ¨æ€æ‰¹æ¬¡å¤§å°è°ƒæ•´ (ç›®æ ‡CPUä½¿ç”¨ç‡: {args.target_cpu_usage}%)")
            
            # ä½¿ç”¨åŠ¨æ€æ‰¹æ¬¡è®­ç»ƒå™¨
            dynamic_trainer = DynamicBatchTrainer(
                model=model,
                train_data_info=(X_train, Y_train, init_states_train),
                val_data_info=(X_val, Y_val, init_states_val),
                initial_batch_size=batch_size
            )
            
            # æ·»åŠ åŠ¨æ€æ‰¹æ¬¡å›è°ƒï¼ˆæ›¿æ¢CPUç›‘æ§ï¼‰
            dynamic_callbacks = [progress_callback, early_stopping, lr_scheduler]
            dynamic_callbacks.append(create_dynamic_batch_callback(
                target_cpu_usage=args.target_cpu_usage,
                min_batch_size=16,
                max_batch_size=min(512, len(X_train)),
                verbose=True
            ))
            
            history = dynamic_trainer.fit(
                epochs=args.epochs,
                initial_epoch=epoch_offset,
                verbose=1,
                callbacks=dynamic_callbacks,
                use_multiprocessing=True,
                workers=min(num_workers, 32),
                max_queue_size=max(20, num_workers * 2)
            )
            
        elif num_workers is not None:  # CPUæ¨¡å¼ - ä¼ ç»Ÿè®­ç»ƒ
            # CPUè®­ç»ƒé…ç½® - æ›´æ¿€è¿›çš„å¤šè¿›ç¨‹è®¾ç½®
            max_queue = max(20, num_workers * 2)  # å¢åŠ é˜Ÿåˆ—å¤§å°
            cpu_workers = min(num_workers, 32)    # é™åˆ¶æœ€å¤§è¿›ç¨‹æ•°é¿å…è¿‡åº¦å¼€é”€
            print(f"CPUè®­ç»ƒé…ç½®: workers={cpu_workers}, max_queue_size={max_queue}")
            
            history = model.fit(
                 train_dataset,
                 validation_data=val_dataset,
                 epochs=args.epochs,
                 initial_epoch=epoch_offset,
                 verbose=1,
                 callbacks=callbacks,
                 use_multiprocessing=True,  # å¯ç”¨å¤šè¿›ç¨‹
                 workers=cpu_workers,
                 max_queue_size=max_queue
             )
        else:  # GPUæ¨¡å¼
            env_type = detect_environment()
            if env_type == 'local':
                # æœ¬åœ°GPUè®­ç»ƒé…ç½® - ä¼˜åŒ–æ€§èƒ½
                print(f"ğŸ  æœ¬åœ°GPUè®­ç»ƒé…ç½®: ç¦ç”¨å¤šè¿›ç¨‹ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨")
                history = model.fit(
                    train_dataset,
                    validation_data=val_dataset,
                    epochs=args.epochs,
                    initial_epoch=epoch_offset,
                    verbose=1,
                    callbacks=callbacks,
                    use_multiprocessing=False,  # æœ¬åœ°GPUé¿å…å¤šè¿›ç¨‹ç«äº‰
                    workers=1,                  # å•å·¥ä½œçº¿ç¨‹
                    max_queue_size=2            # è¾ƒå°çš„é˜Ÿåˆ—å‡å°‘å†…å­˜å ç”¨
                )
            else:
                # äº‘GPUè®­ç»ƒé…ç½® - æ ‡å‡†è®¾ç½®
                print(f"â˜ï¸  äº‘GPUè®­ç»ƒé…ç½®: æ ‡å‡†è®¾ç½®")
                history = model.fit(
                    train_dataset,
                    validation_data=val_dataset,
                    epochs=args.epochs,
                    initial_epoch=epoch_offset,
                    verbose=1,
                    callbacks=callbacks,
                    use_multiprocessing=False,
                    workers=1,
                    max_queue_size=10
                )
        
        # è®­ç»ƒå®Œæˆåæœ€ç»ˆä¿å­˜
        print("\nè®­ç»ƒå®Œæˆï¼Œæ‰§è¡Œæœ€ç»ˆä¿å­˜...")
        final_model_path = progress_callback._safe_save_model(model, is_best=False)
        
        # ä¿å­˜æœ€ç»ˆçš„è®­ç»ƒå†å²å’Œå›¾è¡¨
        progress_callback._save_training_history()
        progress_callback._plot_training_history()
        
        # ç»˜åˆ¶æœ€ç»ˆè®­ç»ƒæ€»ç»“
        plot_final_training_summary(
            history, epoch_offset, args.epochs,
            progress_callback, dataset_dir
        )
        
        # æ‰“å°è®­ç»ƒæ€»ç»“
        print_training_summary(
            progress_callback, dataset_dir,
            best_model_name, model_name
        )

if __name__ == '__main__':
    main()